{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b1b0f0",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b500f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "import string\n",
    "import unidecode\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215a331",
   "metadata": {},
   "source": [
    "**Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9063d8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataline</th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
       "0         1  Henry IV               NaN          NaN            NaN   \n",
       "1         2  Henry IV               NaN          NaN            NaN   \n",
       "2         3  Henry IV               NaN          NaN            NaN   \n",
       "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
       "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
       "\n",
       "                                                text  \n",
       "0                                              ACT I  \n",
       "1                       SCENE I. London. The palace.  \n",
       "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "3             So shaken as we are, so wan with care,  \n",
       "4         Find we a time for frighted peace to pant,  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Shakespeare_data.csv')\n",
    "data = data.rename(columns={'PlayerLine': 'text'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b68baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 111396 sentences in dataset. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                ACT I\n",
       "1                         SCENE I. London. The palace.\n",
       "2    Enter KING HENRY, LORD JOHN OF LANCASTER, the ...\n",
       "3               So shaken as we are, so wan with care,\n",
       "4           Find we a time for frighted peace to pant,\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us keep only the column that we need for model training, text generation\n",
    "\n",
    "data = data['text']\n",
    "length = len(data)\n",
    "print(f\"There are {length} sentences in dataset.\", '\\n')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50970af",
   "metadata": {},
   "source": [
    "**GPU checking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7580b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is found and connected!\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available to do the training with it for faster calculations\n",
    "# otherwise use CPU\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"GPU is found and connected!\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.cuda.device(0)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU, will do training with CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933b38ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111396"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329fb06",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d43b736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37805"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list(data[:5000]) #[:100]\n",
    "\n",
    "# Define function to join all sentences into one long sentence\n",
    "def joinStrings(text):\n",
    "    return ' '.join(string for string in text)\n",
    "text = joinStrings(text)\n",
    "\n",
    "# number of words in our data\n",
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0be10bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACT',\n",
       " 'I',\n",
       " 'SCENE',\n",
       " 'I.',\n",
       " 'London.',\n",
       " 'The',\n",
       " 'palace.',\n",
       " 'Enter',\n",
       " 'KING',\n",
       " 'HENRY,',\n",
       " 'LORD',\n",
       " 'JOHN',\n",
       " 'OF',\n",
       " 'LANCASTER,',\n",
       " 'the',\n",
       " 'EARL',\n",
       " 'of',\n",
       " 'WESTMORELAND,',\n",
       " 'SIR',\n",
       " 'WALTER',\n",
       " 'BLUNT,',\n",
       " 'and',\n",
       " 'others',\n",
       " 'So',\n",
       " 'shaken',\n",
       " 'as',\n",
       " 'we',\n",
       " 'are,',\n",
       " 'so',\n",
       " 'wan',\n",
       " 'with',\n",
       " 'care,',\n",
       " 'Find',\n",
       " 'we',\n",
       " 'a',\n",
       " 'time',\n",
       " 'for',\n",
       " 'frighted',\n",
       " 'peace',\n",
       " 'to',\n",
       " 'pant,',\n",
       " 'And',\n",
       " 'breathe',\n",
       " 'short-winded',\n",
       " 'accents',\n",
       " 'of',\n",
       " 'new',\n",
       " 'broils',\n",
       " 'To',\n",
       " 'be',\n",
       " 'commenced',\n",
       " 'in',\n",
       " 'strands',\n",
       " 'afar',\n",
       " 'remote.',\n",
       " 'No',\n",
       " 'more',\n",
       " 'the',\n",
       " 'thirsty',\n",
       " 'entrance',\n",
       " 'of',\n",
       " 'this',\n",
       " 'soil',\n",
       " 'Shall',\n",
       " 'daub',\n",
       " 'her',\n",
       " 'lips',\n",
       " 'with',\n",
       " 'her',\n",
       " 'own',\n",
       " \"children's\",\n",
       " 'blood,',\n",
       " 'Nor',\n",
       " 'more',\n",
       " 'shall',\n",
       " 'trenching',\n",
       " 'war',\n",
       " 'channel',\n",
       " 'her',\n",
       " 'fields,',\n",
       " 'Nor',\n",
       " 'bruise',\n",
       " 'her',\n",
       " 'flowerets',\n",
       " 'with',\n",
       " 'the',\n",
       " 'armed',\n",
       " 'hoofs',\n",
       " 'Of',\n",
       " 'hostile',\n",
       " 'paces:',\n",
       " 'those',\n",
       " 'opposed',\n",
       " 'eyes,',\n",
       " 'Which,',\n",
       " 'like',\n",
       " 'the',\n",
       " 'meteors',\n",
       " 'of',\n",
       " 'a',\n",
       " 'troubled',\n",
       " 'heaven,',\n",
       " 'All',\n",
       " 'of',\n",
       " 'one',\n",
       " 'nature,',\n",
       " 'of',\n",
       " 'one',\n",
       " 'substance',\n",
       " 'bred,',\n",
       " 'Did',\n",
       " 'lately',\n",
       " 'meet',\n",
       " 'in',\n",
       " 'the',\n",
       " 'intestine',\n",
       " 'shock',\n",
       " 'And',\n",
       " 'furious',\n",
       " 'close',\n",
       " 'of',\n",
       " 'civil',\n",
       " 'butchery',\n",
       " 'Shall',\n",
       " 'now,',\n",
       " 'in',\n",
       " 'mutual',\n",
       " 'well-beseeming',\n",
       " 'ranks,',\n",
       " 'March',\n",
       " 'all',\n",
       " 'one',\n",
       " 'way',\n",
       " 'and',\n",
       " 'be',\n",
       " 'no',\n",
       " 'more',\n",
       " 'opposed',\n",
       " 'Against',\n",
       " 'acquaintance,',\n",
       " 'kindred',\n",
       " 'and',\n",
       " 'allies:',\n",
       " 'The',\n",
       " 'edge',\n",
       " 'of',\n",
       " 'war,',\n",
       " 'like',\n",
       " 'an',\n",
       " 'ill-sheathed',\n",
       " 'knife,',\n",
       " 'No',\n",
       " 'more',\n",
       " 'shall',\n",
       " 'cut',\n",
       " 'his',\n",
       " 'master.',\n",
       " 'Therefore,',\n",
       " 'friends,',\n",
       " 'As',\n",
       " 'far',\n",
       " 'as',\n",
       " 'to',\n",
       " 'the',\n",
       " 'sepulchre',\n",
       " 'of',\n",
       " 'Christ,',\n",
       " 'Whose',\n",
       " 'soldier',\n",
       " 'now,',\n",
       " 'under',\n",
       " 'whose',\n",
       " 'blessed',\n",
       " 'cross',\n",
       " 'We',\n",
       " 'are',\n",
       " 'impressed',\n",
       " 'and',\n",
       " 'engaged',\n",
       " 'to',\n",
       " 'fight,',\n",
       " 'Forthwith',\n",
       " 'a',\n",
       " 'power',\n",
       " 'of',\n",
       " 'English',\n",
       " 'shall',\n",
       " 'we',\n",
       " 'levy,',\n",
       " 'Whose',\n",
       " 'arms',\n",
       " 'were',\n",
       " 'moulded',\n",
       " 'in',\n",
       " 'their',\n",
       " \"mothers'\",\n",
       " 'womb',\n",
       " 'To',\n",
       " 'chase',\n",
       " 'these',\n",
       " 'pagans',\n",
       " 'in',\n",
       " 'those',\n",
       " 'holy',\n",
       " 'fields',\n",
       " 'Over',\n",
       " 'whose',\n",
       " 'acres',\n",
       " \"walk'd\",\n",
       " 'those',\n",
       " 'blessed',\n",
       " 'feet',\n",
       " 'Which',\n",
       " 'fourteen',\n",
       " 'hundred',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'were',\n",
       " \"nail'd\",\n",
       " 'For',\n",
       " 'our',\n",
       " 'advantage',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bitter',\n",
       " 'cross.',\n",
       " 'But',\n",
       " 'this',\n",
       " 'our',\n",
       " 'purpose',\n",
       " 'now',\n",
       " 'is',\n",
       " 'twelve',\n",
       " 'month',\n",
       " 'old,',\n",
       " 'And',\n",
       " 'bootless',\n",
       " \"'tis\",\n",
       " 'to',\n",
       " 'tell',\n",
       " 'you',\n",
       " 'we',\n",
       " 'will',\n",
       " 'go:',\n",
       " 'Therefore',\n",
       " 'we',\n",
       " 'meet',\n",
       " 'not',\n",
       " 'now.',\n",
       " 'Then',\n",
       " 'let',\n",
       " 'me',\n",
       " 'hear',\n",
       " 'Of',\n",
       " 'you,',\n",
       " 'my',\n",
       " 'gentle',\n",
       " 'cousin',\n",
       " 'Westmoreland,',\n",
       " 'What',\n",
       " 'yesternight',\n",
       " 'our',\n",
       " 'council',\n",
       " 'did',\n",
       " 'decree',\n",
       " 'In',\n",
       " 'forwarding',\n",
       " 'this',\n",
       " 'dear',\n",
       " 'expedience.',\n",
       " 'My',\n",
       " 'liege,',\n",
       " 'this',\n",
       " 'haste',\n",
       " 'was',\n",
       " 'hot',\n",
       " 'in',\n",
       " 'question,',\n",
       " 'And',\n",
       " 'many',\n",
       " 'limits',\n",
       " 'of',\n",
       " 'the',\n",
       " 'charge',\n",
       " 'set',\n",
       " 'down',\n",
       " 'But',\n",
       " 'yesternight:',\n",
       " 'when',\n",
       " 'all',\n",
       " 'athwart',\n",
       " 'there',\n",
       " 'came',\n",
       " 'A',\n",
       " 'post',\n",
       " 'from',\n",
       " 'Wales',\n",
       " 'loaden',\n",
       " 'with',\n",
       " 'heavy',\n",
       " 'news,',\n",
       " 'Whose',\n",
       " 'worst',\n",
       " 'was,',\n",
       " 'that',\n",
       " 'the',\n",
       " 'noble',\n",
       " 'Mortimer,',\n",
       " 'Leading',\n",
       " 'the',\n",
       " 'men',\n",
       " 'of',\n",
       " 'Herefordshire',\n",
       " 'to',\n",
       " 'fight',\n",
       " 'Against',\n",
       " 'the',\n",
       " 'irregular',\n",
       " 'and',\n",
       " 'wild',\n",
       " 'Glendower,',\n",
       " 'Was',\n",
       " 'by',\n",
       " 'the',\n",
       " 'rude',\n",
       " 'hands',\n",
       " 'of',\n",
       " 'that',\n",
       " 'Welshman',\n",
       " 'taken,',\n",
       " 'A',\n",
       " 'thousand',\n",
       " 'of',\n",
       " 'his',\n",
       " 'people',\n",
       " 'butchered,',\n",
       " 'Upon',\n",
       " 'whose',\n",
       " 'dead',\n",
       " 'corpse',\n",
       " 'there',\n",
       " 'was',\n",
       " 'such',\n",
       " 'misuse,',\n",
       " 'Such',\n",
       " 'beastly',\n",
       " 'shameless',\n",
       " 'transformation,',\n",
       " 'By',\n",
       " 'those',\n",
       " 'Welshwomen',\n",
       " 'done',\n",
       " 'as',\n",
       " 'may',\n",
       " 'not',\n",
       " 'be',\n",
       " 'Without',\n",
       " 'much',\n",
       " 'shame',\n",
       " 'retold',\n",
       " 'or',\n",
       " 'spoken',\n",
       " 'of.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'then',\n",
       " 'that',\n",
       " 'the',\n",
       " 'tidings',\n",
       " 'of',\n",
       " 'this',\n",
       " 'broil',\n",
       " 'Brake',\n",
       " 'off',\n",
       " 'our',\n",
       " 'business',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Holy',\n",
       " 'Land.',\n",
       " 'This',\n",
       " \"match'd\",\n",
       " 'with',\n",
       " 'other',\n",
       " 'did,',\n",
       " 'my',\n",
       " 'gracious',\n",
       " 'lord,',\n",
       " 'For',\n",
       " 'more',\n",
       " 'uneven',\n",
       " 'and',\n",
       " 'unwelcome',\n",
       " 'news',\n",
       " 'Came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'north',\n",
       " 'and',\n",
       " 'thus',\n",
       " 'it',\n",
       " 'did',\n",
       " 'import:',\n",
       " 'On',\n",
       " 'Holy-rood',\n",
       " 'day,',\n",
       " 'the',\n",
       " 'gallant',\n",
       " 'Hotspur',\n",
       " 'there,',\n",
       " 'Young',\n",
       " 'Harry',\n",
       " 'Percy',\n",
       " 'and',\n",
       " 'brave',\n",
       " 'Archibald,',\n",
       " 'That',\n",
       " 'ever-valiant',\n",
       " 'and',\n",
       " 'approved',\n",
       " 'Scot,',\n",
       " 'At',\n",
       " 'Holmedon',\n",
       " 'met,',\n",
       " 'Where',\n",
       " 'they',\n",
       " 'did',\n",
       " 'spend',\n",
       " 'a',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'bloody',\n",
       " 'hour,',\n",
       " 'As',\n",
       " 'by',\n",
       " 'discharge',\n",
       " 'of',\n",
       " 'their',\n",
       " 'artillery,',\n",
       " 'And',\n",
       " 'shape',\n",
       " 'of',\n",
       " 'likelihood,',\n",
       " 'the',\n",
       " 'news',\n",
       " 'was',\n",
       " 'told,',\n",
       " 'For',\n",
       " 'he',\n",
       " 'that',\n",
       " 'brought',\n",
       " 'them,',\n",
       " 'in',\n",
       " 'the',\n",
       " 'very',\n",
       " 'heat',\n",
       " 'And',\n",
       " 'pride',\n",
       " 'of',\n",
       " 'their',\n",
       " 'contention',\n",
       " 'did',\n",
       " 'take',\n",
       " 'horse,',\n",
       " 'Uncertain',\n",
       " 'of',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'any',\n",
       " 'way.',\n",
       " 'Here',\n",
       " 'is',\n",
       " 'a',\n",
       " 'dear,',\n",
       " 'a',\n",
       " 'true',\n",
       " 'industrious',\n",
       " 'friend,',\n",
       " 'Sir',\n",
       " 'Walter',\n",
       " 'Blunt,',\n",
       " 'new',\n",
       " 'lighted',\n",
       " 'from',\n",
       " 'his',\n",
       " 'horse.',\n",
       " \"Stain'd\",\n",
       " 'with',\n",
       " 'the',\n",
       " 'variation',\n",
       " 'of',\n",
       " 'each',\n",
       " 'soil',\n",
       " 'Betwixt',\n",
       " 'that',\n",
       " 'Holmedon',\n",
       " 'and',\n",
       " 'this',\n",
       " 'seat',\n",
       " 'of',\n",
       " 'ours,',\n",
       " 'And',\n",
       " 'he',\n",
       " 'hath',\n",
       " 'brought',\n",
       " 'us',\n",
       " 'smooth',\n",
       " 'and',\n",
       " 'welcome',\n",
       " 'news.',\n",
       " 'The',\n",
       " 'Earl',\n",
       " 'of',\n",
       " 'Douglas',\n",
       " 'is',\n",
       " 'discomfited:',\n",
       " 'Ten',\n",
       " 'thousand',\n",
       " 'bold',\n",
       " 'Scots,',\n",
       " 'two',\n",
       " 'and',\n",
       " 'twenty',\n",
       " 'knights,',\n",
       " \"Balk'd\",\n",
       " 'in',\n",
       " 'their',\n",
       " 'own',\n",
       " 'blood',\n",
       " 'did',\n",
       " 'Sir',\n",
       " 'Walter',\n",
       " 'see',\n",
       " 'On',\n",
       " \"Holmedon's\",\n",
       " 'plains.',\n",
       " 'Of',\n",
       " 'prisoners,',\n",
       " 'Hotspur',\n",
       " 'took',\n",
       " 'Mordake',\n",
       " 'the',\n",
       " 'Earl',\n",
       " 'of',\n",
       " 'Fife,',\n",
       " 'and',\n",
       " 'eldest',\n",
       " 'son',\n",
       " 'To',\n",
       " 'beaten',\n",
       " 'Douglas,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Earl',\n",
       " 'of',\n",
       " 'Athol,',\n",
       " 'Of',\n",
       " 'Murray,',\n",
       " 'Angus,',\n",
       " 'and',\n",
       " 'Menteith:',\n",
       " 'And',\n",
       " 'is',\n",
       " 'not',\n",
       " 'this',\n",
       " 'an',\n",
       " 'honourable',\n",
       " 'spoil?',\n",
       " 'A',\n",
       " 'gallant',\n",
       " 'prize?',\n",
       " 'ha,',\n",
       " 'cousin,',\n",
       " 'is',\n",
       " 'it',\n",
       " 'not?',\n",
       " 'In',\n",
       " 'faith,',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'conquest',\n",
       " 'for',\n",
       " 'a',\n",
       " 'prince',\n",
       " 'to',\n",
       " 'boast',\n",
       " 'of.',\n",
       " 'Yea,',\n",
       " 'there',\n",
       " 'thou',\n",
       " 'makest',\n",
       " 'me',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'makest',\n",
       " 'me',\n",
       " 'sin',\n",
       " 'In',\n",
       " 'envy',\n",
       " 'that',\n",
       " 'my',\n",
       " 'Lord',\n",
       " 'Northumberland',\n",
       " 'Should',\n",
       " 'be',\n",
       " 'the',\n",
       " 'father',\n",
       " 'to',\n",
       " 'so',\n",
       " 'blest',\n",
       " 'a',\n",
       " 'son,',\n",
       " 'A',\n",
       " 'son',\n",
       " 'who',\n",
       " 'is',\n",
       " 'the',\n",
       " 'theme',\n",
       " 'of',\n",
       " \"honour's\",\n",
       " 'tongue,',\n",
       " 'Amongst',\n",
       " 'a',\n",
       " 'grove,',\n",
       " 'the',\n",
       " 'very',\n",
       " 'straightest',\n",
       " 'plant,',\n",
       " 'Who',\n",
       " 'is',\n",
       " 'sweet',\n",
       " \"Fortune's\",\n",
       " 'minion',\n",
       " 'and',\n",
       " 'her',\n",
       " 'pride:',\n",
       " 'Whilst',\n",
       " 'I,',\n",
       " 'by',\n",
       " 'looking',\n",
       " 'on',\n",
       " 'the',\n",
       " 'praise',\n",
       " 'of',\n",
       " 'him,',\n",
       " 'See',\n",
       " 'riot',\n",
       " 'and',\n",
       " 'dishonour',\n",
       " 'stain',\n",
       " 'the',\n",
       " 'brow',\n",
       " 'Of',\n",
       " 'my',\n",
       " 'young',\n",
       " 'Harry.',\n",
       " 'O',\n",
       " 'that',\n",
       " 'it',\n",
       " 'could',\n",
       " 'be',\n",
       " 'proved',\n",
       " 'That',\n",
       " 'some',\n",
       " 'night-tripping',\n",
       " 'fairy',\n",
       " 'had',\n",
       " 'exchanged',\n",
       " 'In',\n",
       " 'cradle-clothes',\n",
       " 'our',\n",
       " 'children',\n",
       " 'where',\n",
       " 'they',\n",
       " 'lay,',\n",
       " 'And',\n",
       " \"call'd\",\n",
       " 'mine',\n",
       " 'Percy,',\n",
       " 'his',\n",
       " 'Plantagenet!',\n",
       " 'Then',\n",
       " 'would',\n",
       " 'I',\n",
       " 'have',\n",
       " 'his',\n",
       " 'Harry,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'mine.',\n",
       " 'But',\n",
       " 'let',\n",
       " 'him',\n",
       " 'from',\n",
       " 'my',\n",
       " 'thoughts.',\n",
       " 'What',\n",
       " 'think',\n",
       " 'you,',\n",
       " 'coz,',\n",
       " 'Of',\n",
       " 'this',\n",
       " 'young',\n",
       " \"Percy's\",\n",
       " 'pride?',\n",
       " 'the',\n",
       " 'prisoners,',\n",
       " 'Which',\n",
       " 'he',\n",
       " 'in',\n",
       " 'this',\n",
       " 'adventure',\n",
       " 'hath',\n",
       " 'surprised,',\n",
       " 'To',\n",
       " 'his',\n",
       " 'own',\n",
       " 'use',\n",
       " 'he',\n",
       " 'keeps,',\n",
       " 'and',\n",
       " 'sends',\n",
       " 'me',\n",
       " 'word,',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'have',\n",
       " 'none',\n",
       " 'but',\n",
       " 'Mordake',\n",
       " 'Earl',\n",
       " 'of',\n",
       " 'Fife.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'his',\n",
       " \"uncle's\",\n",
       " 'teaching,',\n",
       " 'this',\n",
       " 'is',\n",
       " 'Worcester,',\n",
       " 'Malevolent',\n",
       " 'to',\n",
       " 'you',\n",
       " 'in',\n",
       " 'all',\n",
       " 'aspects,',\n",
       " 'Which',\n",
       " 'makes',\n",
       " 'him',\n",
       " 'prune',\n",
       " 'himself,',\n",
       " 'and',\n",
       " 'bristle',\n",
       " 'up',\n",
       " 'The',\n",
       " 'crest',\n",
       " 'of',\n",
       " 'youth',\n",
       " 'against',\n",
       " 'your',\n",
       " 'dignity.',\n",
       " 'But',\n",
       " 'I',\n",
       " 'have',\n",
       " 'sent',\n",
       " 'for',\n",
       " 'him',\n",
       " 'to',\n",
       " 'answer',\n",
       " 'this,',\n",
       " 'And',\n",
       " 'for',\n",
       " 'this',\n",
       " 'cause',\n",
       " 'awhile',\n",
       " 'we',\n",
       " 'must',\n",
       " 'neglect',\n",
       " 'Our',\n",
       " 'holy',\n",
       " 'purpose',\n",
       " 'to',\n",
       " 'Jerusalem.',\n",
       " 'Cousin,',\n",
       " 'on',\n",
       " 'Wednesday',\n",
       " 'next',\n",
       " 'our',\n",
       " 'council',\n",
       " 'we',\n",
       " 'Will',\n",
       " 'hold',\n",
       " 'at',\n",
       " 'Windsor,',\n",
       " 'so',\n",
       " 'inform',\n",
       " 'the',\n",
       " 'lords:',\n",
       " 'But',\n",
       " 'come',\n",
       " 'yourself',\n",
       " 'with',\n",
       " 'speed',\n",
       " 'to',\n",
       " 'us',\n",
       " 'again,',\n",
       " 'For',\n",
       " 'more',\n",
       " 'is',\n",
       " 'to',\n",
       " 'be',\n",
       " 'said',\n",
       " 'and',\n",
       " 'to',\n",
       " 'be',\n",
       " 'done',\n",
       " 'Than',\n",
       " 'out',\n",
       " 'of',\n",
       " 'anger',\n",
       " 'can',\n",
       " 'be',\n",
       " 'uttered.',\n",
       " 'I',\n",
       " 'will,',\n",
       " 'my',\n",
       " 'liege.',\n",
       " 'Exeunt',\n",
       " 'SCENE',\n",
       " 'II.',\n",
       " 'London.',\n",
       " 'An',\n",
       " 'apartment',\n",
       " 'of',\n",
       " 'the',\n",
       " \"Prince's.\",\n",
       " 'Enter',\n",
       " 'the',\n",
       " 'PRINCE',\n",
       " 'OF',\n",
       " 'WALES',\n",
       " 'and',\n",
       " 'FALSTAFF',\n",
       " 'Now,',\n",
       " 'Hal,',\n",
       " 'what',\n",
       " 'time',\n",
       " 'of',\n",
       " 'day',\n",
       " 'is',\n",
       " 'it,',\n",
       " 'lad?',\n",
       " 'Thou',\n",
       " 'art',\n",
       " 'so',\n",
       " 'fat-witted,',\n",
       " 'with',\n",
       " 'drinking',\n",
       " 'of',\n",
       " 'old',\n",
       " 'sack',\n",
       " 'and',\n",
       " 'unbuttoning',\n",
       " 'thee',\n",
       " 'after',\n",
       " 'supper',\n",
       " 'and',\n",
       " 'sleeping',\n",
       " 'upon',\n",
       " 'benches',\n",
       " 'after',\n",
       " 'noon,',\n",
       " 'that',\n",
       " 'thou',\n",
       " 'hast',\n",
       " 'forgotten',\n",
       " 'to',\n",
       " 'demand',\n",
       " 'that',\n",
       " 'truly',\n",
       " 'which',\n",
       " 'thou',\n",
       " 'wouldst',\n",
       " 'truly',\n",
       " 'know.',\n",
       " 'What',\n",
       " 'a',\n",
       " 'devil',\n",
       " 'hast',\n",
       " 'thou',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'the',\n",
       " 'time',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day?',\n",
       " 'Unless',\n",
       " 'hours',\n",
       " 'were',\n",
       " 'cups',\n",
       " 'of',\n",
       " 'sack',\n",
       " 'and',\n",
       " 'minutes',\n",
       " 'capons',\n",
       " 'and',\n",
       " 'clocks',\n",
       " 'the',\n",
       " 'tongues',\n",
       " 'of',\n",
       " 'bawds',\n",
       " 'and',\n",
       " 'dials',\n",
       " 'the',\n",
       " 'signs',\n",
       " 'of',\n",
       " 'leaping-houses',\n",
       " 'and',\n",
       " 'the',\n",
       " 'blessed',\n",
       " 'sun',\n",
       " 'himself',\n",
       " 'a',\n",
       " 'fair',\n",
       " 'hot',\n",
       " 'wench',\n",
       " 'in',\n",
       " 'flame-coloured',\n",
       " 'taffeta,',\n",
       " 'I',\n",
       " 'see',\n",
       " 'no',\n",
       " 'reason',\n",
       " 'why',\n",
       " 'thou',\n",
       " 'shouldst',\n",
       " 'be',\n",
       " 'so',\n",
       " 'superfluous',\n",
       " 'to',\n",
       " 'demand',\n",
       " 'the',\n",
       " 'time',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day.',\n",
       " 'Indeed,',\n",
       " 'you',\n",
       " 'come',\n",
       " 'near',\n",
       " 'me',\n",
       " 'now,',\n",
       " 'Hal,',\n",
       " 'for',\n",
       " 'we',\n",
       " 'that',\n",
       " 'take',\n",
       " 'purses',\n",
       " 'go',\n",
       " 'by',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'and',\n",
       " 'the',\n",
       " 'seven',\n",
       " 'stars,',\n",
       " 'and',\n",
       " 'not',\n",
       " 'by',\n",
       " 'Phoebus,',\n",
       " \"he,'that\",\n",
       " 'wandering',\n",
       " 'knight',\n",
       " 'so',\n",
       " \"fair.'\",\n",
       " 'And,',\n",
       " 'I',\n",
       " 'prithee,',\n",
       " 'sweet',\n",
       " 'wag,',\n",
       " 'when',\n",
       " 'thou',\n",
       " 'art',\n",
       " 'king,',\n",
       " 'as,',\n",
       " 'God',\n",
       " 'save',\n",
       " 'thy',\n",
       " 'grace,--majesty',\n",
       " 'I',\n",
       " 'should',\n",
       " 'say,',\n",
       " 'for',\n",
       " 'grace',\n",
       " 'thou',\n",
       " 'wilt',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad8cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords and punctuation marks to remove them from data\n",
    "\n",
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "        stop_free = \" \".join([i for i in doc.split() if i not in stop])\n",
    "        punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "        return normalized\n",
    "    \n",
    "# filltered sentences without stopwords, punctuations in lemmatized and lowercased \n",
    "test_sentence = clean(text).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "992d69e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24484\n",
      "[(['act', 'i'], 'scene'), (['i', 'scene'], 'i'), (['scene', 'i'], 'london')]\n"
     ]
    }
   ],
   "source": [
    "# Trigrams are a type of n-gram, which are contiguous sequences of n items (words in the context of text)\n",
    "# trigrams are a valuable tool in text analysis because they help to capture local word dependencies\n",
    "\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "chunk_len = len(trigrams)\n",
    "print(chunk_len)\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cccf1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5016 unique words in dataset.\n"
     ]
    }
   ],
   "source": [
    "# Define vocubalary based on data and assign numeric value to each unique word\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "voc_len = len(vocab)\n",
    "print(f'There are {voc_len} unique words in dataset.')\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ff74436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and target pairs to train a neural network for tasks text generation\n",
    "\n",
    "inp = []\n",
    "tar = []\n",
    "\n",
    "for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        inp.append(context_idxs)\n",
    "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        tar.append(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77e54ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for saving, loading above defined input, target\n",
    "\n",
    "# torch.save(inp, 'inp.pt')\n",
    "# torch.save(tar, 'tar.pt')\n",
    "\n",
    "# inp = torch.load('inp.pt', map_location=torch.device('mps'))\n",
    "# tar = torch.load('tar.pt', map_location=torch.device('mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f1c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PyTorch RNN model\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # embed the input data into continuous vector of size hidden_size\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        # model uses bidirectional encoding, it receives both forward and backward hidden states concatenated\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        # project the hidden state output of the RNN into the output space\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "    \n",
    "    # initializes the hidden state as a tensor of zeros\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84c79295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a training function for the RNN model\n",
    "\n",
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden().to(device)\n",
    "    # resets the gradients of the model's parameters to zero\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c].to(device), hidden)\n",
    "        loss += criterion(output, target[c].to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    # updates the model's parameters using the computed gradients\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # returns the average loss per step \n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006d4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate training time\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f47427",
   "metadata": {},
   "source": [
    "The below code is for training the above defined model. I have already trained the model for 300 epochs and saved it under name 'decoder_model'.\n",
    "\n",
    "Let us load the model and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3959f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31m 19s (10 1%) 7.6813]\n",
      "[62m 57s (20 3%) 7.3095]\n",
      "[92m 31s (30 5%) 7.2676]\n",
      "[125m 20s (40 6%) 7.2507]\n",
      "[163m 14s (50 8%) 7.2441]\n",
      "[196m 33s (60 10%) 7.2420]\n",
      "[229m 37s (70 11%) 7.2411]\n",
      "[262m 38s (80 13%) 7.2409]\n",
      "[296m 23s (90 15%) 7.2408]\n",
      "[329m 14s (100 16%) 7.2407]\n",
      "[362m 8s (110 18%) 7.2407]\n",
      "[395m 42s (120 20%) 7.2403]\n",
      "[427m 44s (130 21%) 7.2401]\n",
      "[459m 31s (140 23%) 7.2396]\n",
      "[491m 16s (150 25%) 7.2390]\n",
      "[523m 19s (160 26%) 7.2382]\n",
      "[555m 10s (170 28%) 7.2368]\n",
      "[587m 17s (180 30%) 7.2349]\n",
      "[619m 18s (190 31%) 7.2325]\n",
      "[651m 20s (200 33%) 7.2293]\n",
      "[683m 36s (210 35%) 7.2260]\n",
      "[715m 12s (220 36%) 7.2223]\n",
      "[744m 34s (230 38%) 7.2187]\n",
      "[774m 23s (240 40%) 7.2155]\n",
      "[805m 27s (250 41%) 7.2126]\n",
      "[879m 4s (260 43%) 7.2098]\n",
      "[970m 36s (270 45%) 7.2074]\n",
      "[1046m 35s (280 46%) 7.2056]\n",
      "[1178m 1s (290 48%) 7.2037]\n",
      "[1323m 33s (300 50%) 7.2020]\n"
     ]
    }
   ],
   "source": [
    "# # Start training process of RNN model\n",
    "\n",
    "# n_epochs = 300\n",
    "# print_every = 10\n",
    "# plot_every = 10\n",
    "# hidden_size = 10\n",
    "# n_layers = 5\n",
    "# lr = 0.015\n",
    "\n",
    "# decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "# decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# start = time.time()\n",
    "# all_losses = []\n",
    "# loss_avg = 0\n",
    "# decoder.to(device)\n",
    "# for epoch in range(1, n_epochs + 1):\n",
    "#     loss = train(inp,tar)       \n",
    "#     loss_avg += loss\n",
    "\n",
    "#     if epoch % print_every == 0:\n",
    "#         print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 50, loss))\n",
    "# #         print(evaluate('ge', 200), '\\n')\n",
    "\n",
    "#     if epoch % plot_every == 0:\n",
    "#         all_losses.append(loss_avg / plot_every)\n",
    "#         loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7cbffd9-9e7c-403b-abd6-31afedf892a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x144c51510>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize loss function decrease\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b16193b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function called evaluate that uses a trained RNN language model (decoder) to generate text \n",
    "# based on an initial input string prime_str\n",
    "# function generates text by predicting the next word in the sequence and iteratively appending it to the input string\n",
    "\n",
    "def evaluate(prime_str='king keeps', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden().to(device)\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).to(device)\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9009a921",
   "metadata": {},
   "source": [
    "*Some explanation about the effect of Temperature*:\n",
    "\n",
    "High Temperature (e.g., > 1.0): When the temperature is set to a high value, it increases the likelihood of selecting words with lower scores, making the text generation more random. This means that less likely words have a higher chance of being chosen, leading to more diverse and creative text. However, the text may become less coherent and less focused.\n",
    "\n",
    "\n",
    "Intermediate Temperature (e.g., ~ 1.0): At an intermediate temperature provides a balance between randomness and focusing on likely words. It often results in text that is both creative and coherent.\n",
    "\n",
    "\n",
    "Low Temperature (e.g., < 1.0): When the temperature is set to a low value, it sharpens the distribution, emphasizing words with higher scores and reducing the randomness in text generation. This leads to more deterministic and focused text, with a tendency to stick to more probable words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd3c5fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am host northumberland sphere theme so meet like nimble thou wa in kind planet side sun night walter brought temperd john accent illsheathed scots son meteor business two irregular thou improvident crowned of in shape uneven posterity head coz power no\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('i am', 40, temperature=1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "578a62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the path where you want to save the model\n",
    "# model_path = 'decoder_model'\n",
    "\n",
    "# # Save the model's state_dict\n",
    "# torch.save(decoder.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a90cefbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.weight',\n",
       "              tensor([[-0.5051, -1.0201,  0.3953,  ...,  0.2292, -0.1467, -0.7367],\n",
       "                      [-0.9352,  1.6367, -0.8942,  ...,  1.1072,  0.0025,  1.7083],\n",
       "                      [ 0.7627,  0.1615,  0.6916,  ...,  0.8596, -1.1878, -1.1211],\n",
       "                      ...,\n",
       "                      [-0.2016, -0.7770, -0.0555,  ..., -0.8676,  0.4075, -0.1264],\n",
       "                      [ 0.4194,  0.6764, -0.0937,  ...,  1.5796,  0.5211, -0.2843],\n",
       "                      [-0.0681, -0.7330,  0.5209,  ..., -0.5770,  0.4956, -0.1032]],\n",
       "                     device='mps:0')),\n",
       "             ('gru.weight_ih_l0',\n",
       "              tensor([[-2.0722e-01, -2.8548e-01, -1.5832e-02,  7.7778e-02,  4.3522e-01,\n",
       "                       -3.0609e-01, -1.2243e-01, -3.5237e-01, -1.3664e-01, -2.4907e-01,\n",
       "                        4.4477e-02, -4.0722e-01, -4.9795e-01, -3.3928e-01, -2.2377e-01,\n",
       "                        4.0264e-01,  9.3008e-02, -1.2395e-02,  1.7594e-01, -3.8255e-03],\n",
       "                      [-3.2798e-01, -4.5694e-01,  2.9943e-01,  2.5040e-02, -2.7993e-01,\n",
       "                       -4.2012e-01,  3.1627e-01,  8.1111e-03,  3.5276e-01, -6.2951e-02,\n",
       "                        7.5447e-01,  1.6385e-01,  2.3782e-02, -2.0905e-01,  1.5378e-01,\n",
       "                        4.1343e-01,  9.6505e-02, -5.5108e-02,  5.2396e-03, -1.1536e-01],\n",
       "                      [ 4.0659e-01,  1.4502e-01, -3.8286e-01,  2.6894e-01, -5.2480e-02,\n",
       "                        3.7073e-01, -5.7462e-02,  7.2870e-02, -3.9884e-01, -3.9482e-01,\n",
       "                       -1.7073e-01, -2.1267e-02, -7.2535e-02, -8.5533e-02,  1.1006e-02,\n",
       "                        1.4555e-01,  1.8138e-01, -3.1771e-02, -4.3551e-02,  6.1140e-02],\n",
       "                      [ 5.1370e-01,  1.4501e-01,  1.7282e-01, -4.2420e-01,  1.2236e-01,\n",
       "                        5.4619e-02,  7.0099e-02, -1.6961e-01,  3.9137e-01,  1.2447e-01,\n",
       "                       -3.6017e-01,  3.1413e-01,  3.4205e-01, -3.0330e-01, -2.3263e-01,\n",
       "                        1.2805e-01, -1.5251e-01, -1.3553e-01,  1.9693e-02,  1.2645e-01],\n",
       "                      [-1.4319e-01, -3.2149e-01,  2.7466e-01, -5.2407e-02, -1.7531e-02,\n",
       "                        2.8151e-03,  1.3037e-01,  6.8029e-02,  1.3865e-01, -6.4352e-02,\n",
       "                       -2.1082e-01, -1.9969e-01, -2.1828e-01,  5.1127e-02, -1.4536e-01,\n",
       "                       -2.7203e-01,  1.0978e-01, -1.0892e-01, -2.5340e-01, -1.2364e-01],\n",
       "                      [ 4.4739e-01, -3.1158e-01, -3.2062e-02,  2.4468e-01,  1.0425e-01,\n",
       "                        7.5197e-02, -4.8218e-01,  4.0552e-01, -4.8528e-01,  1.0897e-01,\n",
       "                        1.3157e-01,  3.1360e-01,  1.1571e-01, -1.4117e-02, -7.7362e-02,\n",
       "                       -2.7442e-01, -4.2874e-02, -7.1324e-02, -2.0205e-01, -3.5125e-02],\n",
       "                      [ 1.4854e-01, -2.5203e-02, -5.3974e-01, -3.0768e-01,  4.9411e-01,\n",
       "                       -1.7481e-01, -5.7726e-02, -1.1372e-03,  3.9983e-01,  4.7245e-02,\n",
       "                        1.6264e-01, -3.7364e-01, -2.6776e-01, -4.6303e-01,  1.0067e-01,\n",
       "                       -4.0628e-01,  1.7115e-01, -6.2156e-02,  4.2523e-01, -2.3986e-01],\n",
       "                      [-2.3251e-01, -3.7246e-01, -8.8098e-02,  2.6327e-02,  4.8177e-02,\n",
       "                       -3.6267e-01,  5.0579e-02,  3.9887e-01, -7.2377e-02, -7.1825e-03,\n",
       "                        1.6441e-02,  3.4631e-02,  3.3940e-01, -1.7751e-01,  4.3302e-01,\n",
       "                       -1.6029e-01,  1.9271e-01, -2.1859e-01,  2.2107e-01,  1.2496e-01],\n",
       "                      [-1.0388e-02, -4.6539e-01, -2.2507e-01, -1.2417e-01,  3.7744e-01,\n",
       "                       -4.2340e-02, -4.3841e-01,  3.5339e-02,  1.9829e-01, -1.1215e-01,\n",
       "                        4.2272e-01, -4.5664e-01,  3.4237e-02, -9.1823e-02,  2.2553e-01,\n",
       "                       -3.6303e-01, -2.3282e-01, -3.2915e-01,  1.0240e-01, -3.0613e-02],\n",
       "                      [ 1.2016e-01, -2.7720e-01, -2.3269e-02, -2.9490e-02,  6.7329e-02,\n",
       "                       -1.0469e-01, -4.8197e-01,  1.3182e-02,  2.0729e-01, -1.3147e-01,\n",
       "                       -3.3832e-01,  1.5218e-01,  1.5790e-01, -1.9589e-01, -7.8150e-03,\n",
       "                        5.3293e-01,  1.8254e-01, -4.5671e-01,  3.7514e-01, -1.6476e-01],\n",
       "                      [ 1.1749e-01,  5.2100e-03, -4.5017e-01, -4.0709e-01, -3.1878e-02,\n",
       "                        8.7226e-02, -3.2424e-01, -1.2690e-01,  2.7857e-01, -7.3242e-02,\n",
       "                       -3.4401e-01, -7.7893e-02,  4.5461e-01,  3.1774e-01,  2.5794e-01,\n",
       "                       -3.0173e-01, -6.9254e-02,  1.5663e-01, -2.2533e-01, -1.3515e-01],\n",
       "                      [ 4.3038e-01, -1.1506e-01,  2.6320e-01,  2.7308e-02, -1.3807e-02,\n",
       "                       -3.1274e-01,  2.2000e-01, -1.6668e-01,  3.4818e-01,  3.2159e-01,\n",
       "                       -3.3707e-02,  2.3862e-04,  1.3603e-01,  1.5214e-01,  1.0052e-01,\n",
       "                       -1.3215e-01,  3.0881e-01,  1.5352e-01,  2.6240e-01, -2.2712e-01],\n",
       "                      [ 2.9751e-01,  1.6092e-01,  3.5906e-01, -8.8553e-02,  2.0713e-01,\n",
       "                       -6.9760e-02, -1.2340e-01, -3.5786e-01, -2.5813e-01,  4.8480e-01,\n",
       "                       -5.4879e-02, -4.5176e-02, -5.3758e-02, -5.2059e-01, -5.9039e-02,\n",
       "                       -4.0993e-01,  3.7763e-01, -3.0149e-01,  2.0211e-01, -5.3515e-01],\n",
       "                      [ 8.2677e-02, -1.1782e-01,  9.0298e-02, -2.2447e-01, -1.4135e-01,\n",
       "                       -7.4529e-02,  7.8567e-02, -1.2989e-01,  6.2071e-02,  3.5616e-01,\n",
       "                        3.7408e-01,  4.9722e-02, -9.1390e-02,  4.0991e-01, -7.2642e-02,\n",
       "                       -5.6810e-03,  4.7405e-02,  2.1391e-01,  2.0612e-01, -1.9082e-01],\n",
       "                      [-3.2706e-01,  4.6999e-01,  5.0055e-01, -5.4010e-01,  4.2060e-01,\n",
       "                        2.4952e-01,  3.5251e-02,  9.1187e-02,  3.0064e-01,  2.1195e-01,\n",
       "                       -4.0212e-01, -2.4759e-02, -4.3573e-01,  4.6039e-01,  1.0176e-02,\n",
       "                        2.2791e-01, -1.6788e-02, -1.0749e-01,  4.3912e-01, -3.6899e-01],\n",
       "                      [ 4.4515e-01, -3.2272e-01, -1.8138e-01,  3.3431e-01, -4.4177e-01,\n",
       "                       -2.8349e-01, -4.8074e-02, -6.2084e-03, -6.8176e-02, -8.2490e-03,\n",
       "                       -4.1727e-02,  4.6295e-01,  2.1287e-01, -4.5661e-01,  1.2023e-01,\n",
       "                       -3.6530e-02, -5.6204e-02,  4.6884e-01, -5.1683e-01,  2.3197e-01],\n",
       "                      [-2.7811e-01, -1.8887e-01,  1.1447e-01, -2.4615e-01, -2.8234e-01,\n",
       "                        1.6345e-01,  1.3916e-01,  1.3742e-01,  3.7423e-02,  4.5115e-01,\n",
       "                       -1.6142e-01,  2.9839e-01,  6.7150e-02, -3.5671e-01, -8.5544e-02,\n",
       "                       -3.9457e-02,  2.3355e-01,  6.9740e-02,  2.1687e-01,  3.0164e-01],\n",
       "                      [ 6.0159e-02, -5.4304e-02,  4.9225e-02,  2.3508e-01,  5.8446e-02,\n",
       "                       -2.9605e-01, -4.6324e-01,  3.6147e-01,  4.4336e-01, -1.4150e-01,\n",
       "                       -1.4631e-01,  2.2610e-01,  3.6611e-01, -2.4494e-01, -4.0382e-02,\n",
       "                        2.6537e-01,  3.9941e-01, -4.6435e-01, -5.1967e-01,  1.1410e-01],\n",
       "                      [ 8.1023e-03, -3.4622e-01, -7.5506e-02,  1.3061e-01,  3.4148e-01,\n",
       "                       -4.5470e-02, -5.6481e-02, -1.5097e-01, -4.5001e-01, -1.4182e-01,\n",
       "                        1.6486e-01,  4.1872e-01, -4.3903e-01, -8.7377e-02,  2.1190e-01,\n",
       "                        4.4266e-01,  9.7334e-02,  2.8880e-01,  4.2284e-01, -1.7681e-06],\n",
       "                      [-1.2260e-01,  1.5182e-02,  2.0334e-01,  2.7460e-01, -5.9093e-02,\n",
       "                        4.0614e-01, -1.9821e-01, -1.4966e-01, -3.4350e-01,  1.2417e-01,\n",
       "                        3.4972e-01,  1.0511e-01, -4.2305e-01,  4.2095e-01, -3.1709e-02,\n",
       "                       -7.7536e-02, -2.3497e-01,  1.4080e-01, -3.3757e-01, -1.7431e-01],\n",
       "                      [ 3.0086e-02,  4.2299e-02, -2.9406e-01, -2.7099e-01,  6.4152e-02,\n",
       "                        2.6361e-02, -2.1121e-01, -5.4441e-02, -2.0695e-02, -3.7192e-02,\n",
       "                       -2.0491e-01, -3.1980e-02,  4.3332e-01,  4.1896e-01,  1.9470e-01,\n",
       "                       -3.6718e-01, -2.1186e-01,  3.3148e-01, -4.9151e-01,  9.3265e-02],\n",
       "                      [ 2.8357e-01,  3.0543e-02,  3.8515e-01,  1.9602e-01,  1.0625e-01,\n",
       "                       -4.2364e-01,  4.0359e-01,  5.7316e-02,  1.8480e-01,  1.6842e-01,\n",
       "                       -2.7712e-01,  8.7497e-02,  1.1831e-02,  3.4581e-01, -1.8594e-01,\n",
       "                       -9.0346e-02,  3.1949e-01,  4.4835e-01, -1.4857e-01, -4.7257e-01],\n",
       "                      [ 2.8394e-01,  2.4142e-01,  2.0381e-01, -7.6461e-02, -4.8871e-03,\n",
       "                       -4.1133e-02, -9.6393e-02, -3.9481e-01, -4.1523e-01,  3.0915e-01,\n",
       "                       -1.0743e-01,  1.7025e-01, -1.3613e-01, -3.5063e-01, -4.9740e-02,\n",
       "                       -3.4310e-01,  3.6554e-01,  5.6390e-02, -5.4203e-03, -3.2166e-01],\n",
       "                      [-1.5837e-01, -1.4168e-01, -9.6962e-02, -2.0665e-01, -1.0641e-01,\n",
       "                        2.0145e-01, -1.0494e-01, -3.5992e-01, -1.4285e-01,  3.9708e-01,\n",
       "                        1.9291e-01,  1.5599e-02, -2.4241e-01,  3.8607e-01, -1.8104e-01,\n",
       "                       -3.0411e-02,  4.7184e-02,  1.2664e-01,  1.4114e-01, -4.1461e-01],\n",
       "                      [ 2.0286e-01, -3.1949e-01, -5.0898e-01,  3.1973e-01, -1.7925e-01,\n",
       "                       -1.7258e-02,  1.4552e-01,  5.5592e-03, -4.5500e-02, -4.7372e-02,\n",
       "                        4.5403e-02,  4.0586e-02,  3.0551e-01, -2.9029e-01,  6.8500e-02,\n",
       "                       -1.0202e-02, -1.3751e-01, -8.4754e-03, -1.3396e-02,  1.9071e-01],\n",
       "                      [ 4.0046e-01, -2.3451e-02,  3.7934e-02,  4.5854e-01, -3.1458e-01,\n",
       "                       -2.5790e-01,  6.7678e-02,  8.5933e-02, -2.3509e-01,  7.7520e-02,\n",
       "                       -5.8620e-02,  4.9739e-01,  2.1465e-01, -3.8699e-01,  1.8607e-01,\n",
       "                       -1.6757e-01, -6.6923e-02,  3.7133e-01, -3.3720e-01,  1.0907e-01],\n",
       "                      [ 1.7493e-01, -2.4069e-01, -8.9606e-03,  5.2983e-03,  1.2503e-01,\n",
       "                        4.2404e-02,  5.3712e-01,  1.4964e-01,  3.2564e-01, -4.2818e-02,\n",
       "                       -1.8550e-01, -4.1356e-01,  1.1657e-01,  1.2283e-01,  6.1437e-04,\n",
       "                       -1.3905e-01, -1.7010e-02, -1.7920e-01,  1.4372e-01,  3.5181e-02],\n",
       "                      [-1.0465e-01, -3.0275e-02, -1.2194e-01,  1.9494e-01,  1.3815e-01,\n",
       "                       -2.8377e-01, -3.3801e-01,  1.9706e-01,  4.5970e-02, -1.0938e-01,\n",
       "                        2.8469e-02,  3.6707e-01,  4.4093e-01, -3.0086e-01, -1.7680e-01,\n",
       "                        4.0760e-01,  3.3288e-01, -3.8768e-01, -3.7475e-01,  1.1301e-01],\n",
       "                      [-2.0786e-02, -1.2067e-03,  1.0190e-01, -1.7744e-01, -1.3870e-02,\n",
       "                        4.1744e-02,  1.1036e-01,  5.7749e-02,  1.6488e-01,  2.9625e-02,\n",
       "                        9.8690e-02, -3.6455e-01,  7.8600e-02, -2.5736e-02,  3.5495e-02,\n",
       "                       -2.8723e-01, -1.8225e-02, -2.7956e-01, -3.5986e-01,  3.6594e-02],\n",
       "                      [ 8.5260e-02, -1.1796e-01, -4.0218e-01, -1.6198e-01, -1.2641e-02,\n",
       "                       -4.3770e-01,  3.4253e-01, -4.9232e-02,  4.6323e-01,  1.2680e-01,\n",
       "                       -3.4508e-01, -1.1105e-01,  1.7922e-01, -3.1533e-01, -8.0955e-02,\n",
       "                       -5.7738e-02,  2.4497e-01, -4.3947e-02,  2.8539e-01,  1.6990e-01]],\n",
       "                     device='mps:0')),\n",
       "             ('gru.weight_hh_l0',\n",
       "              tensor([[-0.0671, -0.4743, -0.0736, -0.3749,  0.3856,  0.0751,  0.3728, -0.3394,\n",
       "                        0.0663,  0.4213],\n",
       "                      [ 0.2639, -0.1187,  0.3094, -0.0131,  0.0473,  0.2625, -0.1348, -0.1181,\n",
       "                       -0.0037, -0.1243],\n",
       "                      [-0.1192,  0.0871,  0.0127, -0.0014,  0.1773, -0.0925, -0.3431, -0.4639,\n",
       "                       -0.1108,  0.1338],\n",
       "                      [-0.4652,  0.2302, -0.0317,  0.1330, -0.0323, -0.0541,  0.0189, -0.3070,\n",
       "                       -0.1073,  0.2670],\n",
       "                      [ 0.0870,  0.4081,  0.2078,  0.2499, -0.3394,  0.1525,  0.4188,  0.3575,\n",
       "                       -0.1004,  0.2623],\n",
       "                      [ 0.4946, -0.1493,  0.0226, -0.0901,  0.0254, -0.1837,  0.2012, -0.0944,\n",
       "                        0.5348,  0.2831],\n",
       "                      [-0.0423, -0.2186, -0.0680,  0.1025, -0.0950, -0.1827, -0.2904,  0.0073,\n",
       "                        0.0717,  0.1820],\n",
       "                      [ 0.0473,  0.0784,  0.0341, -0.2102,  0.0409, -0.0808,  0.4559, -0.0039,\n",
       "                        0.2532,  0.4835],\n",
       "                      [ 0.0282, -0.0678, -0.3946,  0.1550,  0.4155, -0.0643, -0.2579,  0.0928,\n",
       "                       -0.0487,  0.3532],\n",
       "                      [-0.2477, -0.0606, -0.2919, -0.1308,  0.2753, -0.0231,  0.0681, -0.4760,\n",
       "                        0.0620,  0.2024],\n",
       "                      [-0.4570, -0.0986, -0.1342, -0.0240, -0.1460,  0.0355, -0.3513, -0.2206,\n",
       "                        0.4299,  0.2223],\n",
       "                      [ 0.2245,  0.1654,  0.0480,  0.0708,  0.0146,  0.0264, -0.1674, -0.0845,\n",
       "                       -0.0857,  0.1329],\n",
       "                      [ 0.2957, -0.4414, -0.5108, -0.2180,  0.3275, -0.1926, -0.1059, -0.3961,\n",
       "                        0.2720,  0.1151],\n",
       "                      [-0.1563, -0.2487, -0.2938, -0.3784, -0.3891,  0.1374,  0.0067,  0.4885,\n",
       "                        0.2852, -0.0887],\n",
       "                      [ 0.1526, -0.1022, -0.1178, -0.0706,  0.0172,  0.3029,  0.0200,  0.1159,\n",
       "                        0.2166, -0.0356],\n",
       "                      [-0.1886,  0.4289, -0.5005,  0.4513, -0.0588, -0.2630,  0.2983, -0.5165,\n",
       "                       -0.1367,  0.4550],\n",
       "                      [-0.1016,  0.2401, -0.1846, -0.0603,  0.3110, -0.0950, -0.1168, -0.3495,\n",
       "                        0.2209,  0.3737],\n",
       "                      [ 0.0117,  0.3430, -0.2826,  0.2381,  0.2288, -0.2238, -0.0185, -0.2644,\n",
       "                        0.1589, -0.0109],\n",
       "                      [ 0.0117,  0.4667,  0.0680, -0.3431,  0.0092, -0.2829,  0.2228, -0.0614,\n",
       "                        0.2840, -0.0568],\n",
       "                      [ 0.1169,  0.3609, -0.0017,  0.1215,  0.3571, -0.1432,  0.2768, -0.0689,\n",
       "                        0.3193, -0.0250],\n",
       "                      [ 0.0700,  0.1211, -0.0501,  0.1148,  0.0966,  0.3610, -0.1069,  0.3171,\n",
       "                       -0.1755, -0.2691],\n",
       "                      [ 0.1010, -0.4388,  0.0365, -0.2820, -0.2379,  0.2378, -0.0499,  0.2576,\n",
       "                       -0.2014, -0.0377],\n",
       "                      [ 0.2009, -0.3340,  0.4939, -0.1475, -0.0969,  0.2151,  0.4652,  0.0933,\n",
       "                       -0.2029, -0.0418],\n",
       "                      [ 0.2639, -0.1707, -0.1429, -0.1491, -0.4915,  0.1813,  0.1328,  0.1856,\n",
       "                       -0.3029, -0.1847],\n",
       "                      [-0.2225,  0.3823, -0.1295,  0.1048,  0.0823, -0.4519,  0.0174, -0.0274,\n",
       "                        0.2307,  0.3664],\n",
       "                      [-0.0635,  0.0849,  0.3888, -0.1717, -0.2342,  0.1835,  0.2341,  0.4826,\n",
       "                       -0.5012, -0.2306],\n",
       "                      [-0.1406, -0.1746, -0.2635, -0.0996,  0.2294, -0.2663, -0.0717, -0.4378,\n",
       "                        0.5072, -0.0579],\n",
       "                      [-0.0529, -0.2900, -0.0309, -0.1019,  0.1270,  0.0156, -0.1468, -0.0921,\n",
       "                       -0.1449, -0.4266],\n",
       "                      [-0.2505, -0.0117,  0.0481, -0.0569,  0.3274, -0.4947, -0.4006, -0.3974,\n",
       "                        0.2899, -0.0287],\n",
       "                      [-0.2119, -0.0600,  0.1042, -0.1161,  0.4112, -0.0105,  0.1111, -0.3913,\n",
       "                       -0.0507,  0.1939]], device='mps:0')),\n",
       "             ('gru.bias_ih_l0',\n",
       "              tensor([ 0.1387, -0.4289,  0.1347,  0.0593, -0.0390, -0.2022, -0.0007,  0.0613,\n",
       "                      -0.1338,  0.0187, -0.1374, -0.1073,  0.1944, -0.0388,  0.1572,  0.2583,\n",
       "                       0.3459, -0.0408,  0.3551,  0.4550, -0.2400, -0.0312, -0.2459, -0.0591,\n",
       "                       0.3802, -0.2867, -0.2092, -0.3176,  0.4043,  0.2988], device='mps:0')),\n",
       "             ('gru.bias_hh_l0',\n",
       "              tensor([ 0.0420, -0.0685,  0.4489, -0.0874, -0.4516, -0.3187, -0.0541,  0.0726,\n",
       "                       0.1053,  0.0543, -0.0377, -0.0121, -0.0781, -0.3293,  0.3037,  0.2492,\n",
       "                      -0.0671,  0.4664,  0.3429,  0.4841, -0.3960, -0.0313, -0.1230, -0.1498,\n",
       "                       0.0185,  0.0321,  0.0766, -0.4074,  0.2922,  0.3667], device='mps:0')),\n",
       "             ('gru.weight_ih_l1',\n",
       "              tensor([[-0.2917,  0.0086,  0.0584, -0.5540,  0.3005,  0.2027,  0.1371, -0.0229,\n",
       "                        0.1655,  0.4041],\n",
       "                      [-0.3399,  0.1188,  0.1001, -0.0128,  0.4418, -0.4041,  0.1622, -0.3276,\n",
       "                       -0.2357,  0.2514],\n",
       "                      [-0.2091,  0.0311, -0.4212,  0.1668, -0.0791, -0.1651, -0.2331, -0.1074,\n",
       "                        0.1396,  0.1900],\n",
       "                      [ 0.0795, -0.0334, -0.3036,  0.0987, -0.0484, -0.4193, -0.0494, -0.0918,\n",
       "                        0.0028, -0.0377],\n",
       "                      [-0.0160, -0.2125, -0.2107, -0.0701, -0.0830, -0.0932,  0.0327, -0.0883,\n",
       "                        0.1078,  0.3485],\n",
       "                      [-0.2151,  0.2779, -0.4108, -0.0479, -0.0977,  0.0788, -0.1692, -0.3552,\n",
       "                        0.0718, -0.1518],\n",
       "                      [ 0.2016,  0.0243,  0.4216, -0.3091, -0.2281,  0.2739,  0.2792,  0.0988,\n",
       "                       -0.2138,  0.1010],\n",
       "                      [ 0.4419, -0.5124,  0.0209, -0.0962, -0.0847,  0.1285,  0.3493,  0.4542,\n",
       "                        0.1030, -0.3780],\n",
       "                      [-0.3338, -0.2850,  0.0724,  0.2538, -0.1216,  0.0242, -0.2507,  0.0524,\n",
       "                        0.3429,  0.1113],\n",
       "                      [-0.3303,  0.3444, -0.1175, -0.0165,  0.4218, -0.1836,  0.0281, -0.1012,\n",
       "                        0.0585,  0.1887],\n",
       "                      [ 0.3474,  0.1634,  0.0083, -0.1100,  0.3480,  0.6998, -0.1822,  0.1037,\n",
       "                        0.5047, -0.2130],\n",
       "                      [-0.0063, -0.0827,  0.0570,  0.1581, -0.3008,  0.2411,  0.2538, -0.0197,\n",
       "                       -0.3082,  0.2426],\n",
       "                      [ 0.0517,  0.1803,  0.2862,  0.2007,  0.1341,  0.1671, -0.1413, -0.1805,\n",
       "                        0.0426,  0.0313],\n",
       "                      [ 0.0402,  0.1483,  0.0591, -0.0809, -0.0798,  0.3184,  0.2841,  0.3265,\n",
       "                       -0.2715,  0.0619],\n",
       "                      [ 0.3663,  0.0035, -0.4698, -0.3947, -0.4746,  0.4681, -0.1203,  0.1963,\n",
       "                       -0.0552, -0.0618],\n",
       "                      [ 0.4388,  0.1596,  0.0713, -0.1097,  0.3676,  0.2857,  0.0957,  0.2842,\n",
       "                       -0.0745,  0.0564],\n",
       "                      [-0.5445, -0.1987,  0.0299,  0.4129,  0.0310,  0.0945, -0.1735, -0.3875,\n",
       "                        0.4778, -0.0618],\n",
       "                      [ 0.5254, -0.0632, -0.0726,  0.2110, -0.0449,  0.2585, -0.5458,  0.0923,\n",
       "                       -0.0692, -0.0756],\n",
       "                      [ 0.1173, -0.3968,  0.1831, -0.1904, -0.2390,  0.3299, -0.5178,  0.6302,\n",
       "                        0.0845, -0.2353],\n",
       "                      [ 0.4346,  0.3775, -0.0068, -0.3019,  0.1288,  0.0862,  0.1030, -0.0435,\n",
       "                       -0.0233,  0.3996],\n",
       "                      [-0.4067,  0.0747, -0.2470,  0.3692,  0.0110, -0.0662,  0.0743, -0.3748,\n",
       "                       -0.0525,  0.4012],\n",
       "                      [ 0.3458,  0.3067,  0.3181,  0.2368,  0.1173, -0.0050, -0.3083, -0.1444,\n",
       "                        0.0241, -0.0328],\n",
       "                      [ 0.3560,  0.0329,  0.4548, -0.0104, -0.1002, -0.0138,  0.3299,  0.1142,\n",
       "                       -0.4046, -0.3508],\n",
       "                      [ 0.0495, -0.0539,  0.1243, -0.0793, -0.2405,  0.0889,  0.1565,  0.4061,\n",
       "                       -0.2175, -0.2560],\n",
       "                      [ 0.3022, -0.2781, -0.0398, -0.1319, -0.4770,  0.3192, -0.1144,  0.3523,\n",
       "                       -0.2008, -0.0120],\n",
       "                      [ 0.3806,  0.0983,  0.2944,  0.1411,  0.0977,  0.2609,  0.2740,  0.4129,\n",
       "                       -0.3753, -0.3869],\n",
       "                      [-0.1521,  0.1179, -0.3527, -0.0917,  0.3327, -0.5041, -0.2260, -0.0458,\n",
       "                        0.2178,  0.4289],\n",
       "                      [-0.1610, -0.0739, -0.1557, -0.1490,  0.0529, -0.4343,  0.0587, -0.5396,\n",
       "                       -0.0623,  0.2620],\n",
       "                      [-0.4822,  0.2864, -0.4881,  0.0518,  0.3634, -0.2121, -0.0272, -0.4977,\n",
       "                        0.3087,  0.1266],\n",
       "                      [-0.4180,  0.0051, -0.2959,  0.1974,  0.3955, -0.4531, -0.3405, -0.4113,\n",
       "                        0.1871,  0.0699]], device='mps:0')),\n",
       "             ('gru.weight_hh_l1',\n",
       "              tensor([[-1.5393e-01, -9.0251e-02, -5.6694e-02, -2.5665e-01,  1.3339e-02,\n",
       "                       -2.5505e-02,  2.5802e-01,  1.6703e-01,  2.5285e-01,  1.2803e-01],\n",
       "                      [ 2.2083e-01, -2.3250e-02,  1.4620e-01, -2.2333e-01, -1.8950e-02,\n",
       "                        1.9534e-01,  2.0822e-01,  4.7585e-01,  9.0762e-02,  1.4885e-01],\n",
       "                      [ 4.7014e-01,  1.0492e-01, -5.7795e-02, -4.5739e-01, -1.7509e-01,\n",
       "                       -3.1296e-01, -1.7172e-01,  4.1837e-01,  1.2271e-01,  4.9695e-01],\n",
       "                      [ 5.1470e-02, -1.1194e-02, -2.1229e-01,  7.9070e-02, -3.7742e-01,\n",
       "                       -3.0709e-01, -6.0036e-02,  3.4033e-02,  4.5730e-01,  3.2936e-01],\n",
       "                      [ 4.7017e-01,  2.2051e-01,  2.2201e-02, -4.6256e-01, -1.8202e-01,\n",
       "                       -5.4460e-02,  1.4411e-01,  2.4263e-01,  2.1762e-01,  1.5352e-01],\n",
       "                      [-1.9259e-01,  2.0974e-01,  6.7008e-02, -9.2319e-02, -3.9293e-01,\n",
       "                       -2.1090e-01, -1.6244e-02, -1.4301e-01,  1.1718e-01,  2.5467e-01],\n",
       "                      [-3.9319e-01, -2.1641e-01, -8.6813e-02,  4.8308e-02,  5.1529e-01,\n",
       "                        3.9411e-01, -2.5084e-01, -4.1560e-01,  1.7474e-02, -6.2126e-02],\n",
       "                      [-3.3493e-01,  1.1243e-01,  4.3643e-01, -4.2886e-02,  4.4559e-01,\n",
       "                        1.7668e-01,  2.5798e-03, -3.8175e-01,  8.2013e-02,  3.7901e-02],\n",
       "                      [ 8.1651e-02,  1.5264e-02,  3.4659e-02,  8.5139e-02, -1.9901e-01,\n",
       "                       -1.0176e-01, -7.6635e-02,  1.1795e-01,  3.1083e-01,  4.9099e-01],\n",
       "                      [ 7.9736e-02,  2.4401e-01, -2.1800e-01, -2.8727e-01, -4.5273e-01,\n",
       "                       -1.6339e-01,  2.8138e-01,  1.6050e-01,  3.6019e-02,  9.4028e-02],\n",
       "                      [ 3.1247e-01,  1.6654e-02,  1.9359e-01, -3.5667e-01,  2.5984e-01,\n",
       "                        4.7063e-01, -3.9771e-01,  1.6127e-01,  3.9969e-01,  1.7811e-01],\n",
       "                      [-2.4129e-01,  1.7275e-01,  1.0334e-01,  2.2982e-01,  2.9754e-01,\n",
       "                        9.0004e-02, -1.3406e-01, -8.3810e-02, -3.3793e-01, -8.8983e-02],\n",
       "                      [-4.5283e-01, -3.0047e-01, -1.2333e-01,  4.4484e-01,  2.5145e-01,\n",
       "                       -1.7552e-02, -2.7618e-01, -5.3673e-01,  5.0535e-02, -2.3281e-02],\n",
       "                      [-2.2880e-01,  3.2621e-01,  2.3864e-01, -2.4280e-01,  2.6556e-02,\n",
       "                        3.7972e-01, -9.1001e-02, -2.4951e-01, -2.1106e-01, -2.0796e-01],\n",
       "                      [-6.1883e-02, -4.4973e-02,  8.4883e-02, -1.3859e-01, -4.4073e-01,\n",
       "                        4.1969e-02,  4.7247e-02, -4.8182e-01,  1.7009e-02, -6.0729e-02],\n",
       "                      [ 2.6592e-01, -2.4810e-01, -3.5440e-01, -2.7239e-01,  3.6546e-01,\n",
       "                       -4.4073e-01,  3.2741e-01,  1.6812e-01, -9.5703e-02, -5.2391e-02],\n",
       "                      [ 1.2071e-01, -4.2931e-01, -4.2935e-01, -8.1161e-01, -3.7469e-02,\n",
       "                       -5.7562e-01,  3.5323e-01,  1.0775e+00,  3.5222e-01,  4.4465e-01],\n",
       "                      [-7.7620e-02,  2.4600e-01,  1.0857e-02, -2.3318e-04,  4.5804e-01,\n",
       "                        4.3934e-01,  4.1753e-01, -4.4170e-02, -2.3686e-01,  8.0745e-02],\n",
       "                      [-3.9921e-02, -1.3992e-01,  2.2456e-01, -3.1754e-02,  1.4703e-01,\n",
       "                       -3.2448e-01, -1.0218e-01,  1.8151e-01,  4.6453e-01,  1.4025e-02],\n",
       "                      [ 3.8188e-01,  3.0492e-01,  5.5632e-01,  9.8344e-03, -2.3484e-01,\n",
       "                        5.1185e-01, -1.4815e-01, -2.7273e-01, -1.2452e-01,  1.2054e-01],\n",
       "                      [-2.8844e-02,  2.0527e-01, -8.5538e-02, -3.9303e-01, -5.0499e-02,\n",
       "                       -3.7320e-01,  1.3574e-01,  4.2080e-02,  1.7253e-01,  1.9726e-01],\n",
       "                      [-1.9038e-01, -3.6221e-01,  1.6028e-01,  9.0710e-02,  2.4768e-01,\n",
       "                        1.2426e-01,  8.8436e-02, -4.6563e-01,  5.2770e-02, -1.4770e-01],\n",
       "                      [-2.1985e-01, -8.0435e-02,  7.3319e-02,  3.4105e-01,  2.9718e-01,\n",
       "                        4.6886e-01,  3.4454e-02, -3.4857e-01, -7.2337e-03, -1.7697e-01],\n",
       "                      [-4.7603e-01, -5.2495e-02,  4.4419e-01,  4.3828e-01, -9.6601e-02,\n",
       "                        4.0923e-01, -3.9026e-01, -2.0115e-01, -5.7797e-02, -4.4607e-01],\n",
       "                      [-4.0724e-01, -3.1618e-01,  2.0569e-01,  4.5050e-01,  3.4016e-02,\n",
       "                        3.5264e-01, -4.3349e-01,  7.8804e-02, -9.1883e-02, -3.1991e-01],\n",
       "                      [-1.9853e-01, -2.1299e-01,  2.0944e-01,  1.5692e-01,  3.1316e-01,\n",
       "                        2.0277e-01, -9.0836e-02, -3.6530e-01, -4.0268e-01, -1.5804e-03],\n",
       "                      [-1.1399e-02,  8.7911e-02,  7.1566e-03,  7.2437e-02, -2.4691e-01,\n",
       "                        4.8904e-02,  3.7588e-01,  8.4704e-02,  3.3936e-01,  2.1052e-02],\n",
       "                      [ 3.7337e-01, -1.6284e-01, -4.2582e-01, -7.8987e-02, -1.9896e-01,\n",
       "                       -1.5269e-01, -1.0998e-02,  2.5933e-01, -2.8895e-02,  1.7038e-01],\n",
       "                      [ 5.1618e-01, -1.8453e-01, -4.9044e-01, -6.6371e-02, -3.5034e-01,\n",
       "                       -2.9929e-01, -1.8292e-01,  3.4666e-01,  3.0358e-01,  1.2724e-01],\n",
       "                      [ 1.8853e-01,  1.3759e-01, -4.5669e-01, -4.3555e-01, -1.0625e-01,\n",
       "                       -2.4057e-01,  1.8330e-01,  1.5394e-01,  2.2146e-01,  3.2228e-01]],\n",
       "                     device='mps:0')),\n",
       "             ('gru.bias_ih_l1',\n",
       "              tensor([-0.0243, -0.1468,  0.4031,  0.2692,  0.2184, -0.0828, -0.1273,  0.0049,\n",
       "                       0.0913,  0.4671, -0.0026, -0.2247, -0.1711, -0.1423, -1.3894, -0.7193,\n",
       "                       0.1915, -0.5063, -0.4627, -1.0694,  0.4919, -0.2558, -0.4292, -0.2334,\n",
       "                      -0.2572, -0.2883,  0.3305,  0.5066,  0.4114,  0.3341], device='mps:0')),\n",
       "             ('gru.bias_hh_l1',\n",
       "              tensor([ 0.1105,  0.3058,  0.3372, -0.1159,  0.0068,  0.3457, -0.5055, -0.2023,\n",
       "                       0.1111, -0.0540, -0.2095, -0.0672,  0.0132, -0.0385, -0.9763, -0.5291,\n",
       "                       0.3152, -0.5820, -0.6944, -0.8988,  0.1433,  0.0342, -0.3380, -0.4081,\n",
       "                      -0.1520, -0.0341, -0.0670, -0.0830,  0.0261,  0.4791], device='mps:0')),\n",
       "             ('gru.weight_ih_l2',\n",
       "              tensor([[ 4.2624e-01, -5.2622e-02,  1.0145e-02, -2.9130e-01, -1.6314e-01,\n",
       "                       -3.3367e-01,  3.3380e-01,  5.0623e-01,  2.8606e-01,  3.3598e-01],\n",
       "                      [ 3.8793e-01,  2.4562e-01, -3.2776e-01,  9.3418e-02, -2.2820e-01,\n",
       "                       -6.6352e-03,  1.1338e-01,  7.8033e-02,  1.8262e-01,  4.6755e-01],\n",
       "                      [-8.4579e-02,  7.9629e-02, -1.1397e-01, -1.6308e-01, -9.9776e-02,\n",
       "                       -2.2485e-01,  4.7996e-01,  1.4638e-01,  3.0447e-02,  4.0472e-01],\n",
       "                      [ 1.0847e-01, -7.6220e-02,  1.7274e-01,  4.6556e-01,  3.6422e-01,\n",
       "                        1.3961e-01,  2.1898e-01, -1.0733e-01,  1.1230e-01, -2.7521e-02],\n",
       "                      [-3.0945e-02, -4.9907e-03, -1.6954e-01,  5.5854e-02, -1.4183e-01,\n",
       "                       -3.3673e-01,  2.0504e-01,  1.6819e-01,  6.6495e-02,  3.6532e-01],\n",
       "                      [ 2.5622e-02, -9.5939e-02, -3.5725e-01, -3.1859e-01,  1.0131e-01,\n",
       "                       -1.4759e-01,  2.6606e-01,  4.1978e-01,  3.6173e-01,  1.7788e-01],\n",
       "                      [ 4.1693e-01,  1.8946e-01,  1.9903e-02,  9.7262e-03, -1.7999e-01,\n",
       "                       -4.6409e-01,  2.0240e-01,  3.9942e-01,  1.2435e-01,  1.3545e-01],\n",
       "                      [-3.5732e-02,  2.7939e-01,  5.7130e-02, -4.1429e-02, -1.4900e-02,\n",
       "                       -5.2198e-01,  7.8474e-03,  1.2954e-01,  3.7687e-01,  2.0280e-01],\n",
       "                      [-2.5099e-02,  1.4258e-01, -4.7662e-01, -2.3609e-01, -4.9956e-01,\n",
       "                       -2.1504e-01,  3.6722e-01,  2.1903e-01,  4.4265e-01,  3.9845e-01],\n",
       "                      [ 1.6751e-02,  2.5611e-02, -2.9091e-01, -1.1577e-01, -2.0574e-01,\n",
       "                       -2.0957e-01,  3.2915e-01,  1.3102e-01,  3.0093e-01,  1.7354e-01],\n",
       "                      [-8.4853e-01, -3.7100e-01,  5.7933e-01,  5.4994e-01,  4.8936e-01,\n",
       "                        2.7433e-01, -6.8356e-01, -4.6970e-01, -3.1553e-01, -6.3398e-01],\n",
       "                      [-5.8075e-01, -4.2578e-01,  8.2029e-01,  4.9177e-01,  6.5628e-01,\n",
       "                        3.3177e-01, -3.4643e-01, -3.6067e-01, -7.0224e-01, -4.5733e-01],\n",
       "                      [ 5.0759e-01,  7.9807e-02, -6.1192e-02, -3.1865e-01, -4.1952e-01,\n",
       "                       -2.7699e-01, -2.8339e-03,  1.8560e-01,  2.0080e-01,  5.9677e-01],\n",
       "                      [-4.0440e-01, -4.1376e-01,  5.6657e-01,  1.3064e-01,  5.9791e-01,\n",
       "                        1.1693e-01, -2.5078e-01, -1.0210e+00, -5.6510e-01, -2.4825e-01],\n",
       "                      [-3.0014e-01,  2.8863e-01,  2.3073e-01,  5.8141e-01,  2.4793e-01,\n",
       "                        1.0557e-01, -4.8927e-01, -4.4218e-01, -2.6678e-01, -1.5287e-01],\n",
       "                      [-3.7928e-01, -1.0640e-01,  4.6113e-01,  5.5891e-01,  1.1334e+00,\n",
       "                        6.4383e-01, -6.3690e-01, -5.3642e-01, -8.5886e-01, -9.4098e-01],\n",
       "                      [-7.1571e-01, -3.2177e-01,  1.8325e-01,  1.6651e-01,  1.0245e-01,\n",
       "                        3.5413e-01, -6.2314e-01, -6.1791e-01, -2.3567e-01, -7.5542e-01],\n",
       "                      [ 1.0538e-03, -4.8080e-01, -6.4071e-01, -2.0328e-01, -1.0839e+00,\n",
       "                       -4.0473e-01, -4.8108e-02,  6.6439e-01,  9.3305e-01,  9.2216e-01],\n",
       "                      [-7.1703e-01, -1.1130e-01,  1.0614e-01,  1.4638e-01,  3.6087e-01,\n",
       "                        4.3321e-01, -3.6747e-01, -4.0433e-01,  1.7945e-02, -8.5820e-02],\n",
       "                      [-1.3943e-01,  3.1732e-01,  2.0489e-01,  3.7826e-01,  5.0374e-01,\n",
       "                        2.6085e-01, -2.1097e-01, -5.3368e-01, -3.2963e-01, -1.4125e-01],\n",
       "                      [-3.8351e-01, -1.7306e-01,  2.9332e-01, -6.2828e-02,  3.7039e-01,\n",
       "                        3.4166e-01, -2.6115e-01, -1.5313e-01, -4.0487e-01, -3.1186e-01],\n",
       "                      [-6.9142e-03, -2.5919e-01,  4.3586e-01,  1.2603e-01,  4.1429e-01,\n",
       "                        2.6895e-01, -1.7566e-01, -5.0936e-01,  6.0269e-02, -4.8665e-01],\n",
       "                      [ 8.5738e-02, -6.6536e-02, -4.5482e-01, -2.1463e-01, -4.6752e-01,\n",
       "                        9.0597e-02, -6.9378e-02,  5.1475e-01,  2.4182e-01,  5.8090e-02],\n",
       "                      [ 1.4316e-01,  3.8997e-02, -2.1271e-01, -3.3127e-01, -4.5281e-01,\n",
       "                        1.0003e-01, -3.5771e-02,  2.1013e-01,  1.9033e-01,  3.9220e-01],\n",
       "                      [ 8.0847e-02, -1.6340e-01, -2.8703e-01, -4.0092e-01, -4.4868e-01,\n",
       "                       -4.5593e-01,  3.6723e-01,  2.5450e-01, -8.2706e-02,  4.7397e-01],\n",
       "                      [ 2.2629e-01,  2.1085e-01, -4.6088e-01,  6.4021e-03, -3.6281e-01,\n",
       "                       -4.4462e-01,  1.3540e-01,  1.8926e-01,  2.7206e-01,  4.2494e-01],\n",
       "                      [ 3.4749e-01,  2.4592e-01, -4.7685e-01, -5.0263e-01,  1.7008e-02,\n",
       "                        8.5289e-02,  9.8372e-02,  2.7154e-01,  3.8139e-01,  3.3069e-01],\n",
       "                      [ 3.0867e-02,  1.2054e-02,  1.6105e-01,  3.5518e-01,  1.3576e-01,\n",
       "                       -6.0734e-02, -3.5555e-01, -9.4132e-02, -1.5483e-01, -1.3836e-01],\n",
       "                      [ 3.0532e-01,  3.0207e-01, -4.1463e-01,  4.9958e-03, -2.9291e-01,\n",
       "                       -4.2728e-01,  3.4917e-01,  3.1115e-01,  4.3654e-01, -5.4683e-02],\n",
       "                      [-3.0300e-01,  1.9607e-01,  6.2005e-02,  3.8417e-01,  4.1460e-02,\n",
       "                        3.6240e-01, -4.0887e-01, -1.1839e-01, -3.4559e-01, -2.2983e-01]],\n",
       "                     device='mps:0')),\n",
       "             ('gru.weight_hh_l2',\n",
       "              tensor([[-1.4599e-01, -7.2876e-02,  4.1084e-01,  9.5178e-02,  2.2528e-01,\n",
       "                        1.8993e-01,  4.6717e-01, -1.6757e-01,  1.7399e-01, -4.7256e-01],\n",
       "                      [-4.1153e-01,  8.2943e-02,  1.4505e-01,  2.3966e-01,  1.9609e-01,\n",
       "                        5.3984e-02,  2.9851e-01, -4.7875e-01,  4.6292e-01, -3.6960e-01],\n",
       "                      [-1.7364e-01, -1.5044e-01,  1.4860e-01,  2.7864e-01,  1.1420e-01,\n",
       "                        2.6047e-01,  4.5692e-01, -3.0694e-01,  1.7833e-01, -3.9642e-01],\n",
       "                      [ 2.9045e-01,  1.4103e-01, -2.1512e-01,  1.1496e-02, -2.0474e-02,\n",
       "                       -7.0204e-03, -2.3649e-01,  3.1596e-01, -1.8846e-01,  1.4613e-01],\n",
       "                      [-3.8206e-02, -2.9298e-01, -9.7553e-02,  5.0958e-01,  2.8727e-01,\n",
       "                        2.4455e-01,  2.6436e-01, -3.6859e-02,  1.3484e-03, -4.3137e-01],\n",
       "                      [ 1.8227e-01, -3.1380e-01,  1.4742e-01, -1.0831e-01,  1.5864e-02,\n",
       "                        1.7086e-01,  3.5853e-02,  2.0248e-03,  8.1375e-02, -2.2187e-01],\n",
       "                      [-9.3515e-02, -2.3475e-01,  4.6945e-01,  3.6313e-01,  1.5362e-01,\n",
       "                       -2.7386e-03,  4.0809e-01,  6.8605e-02,  4.0969e-01,  9.8258e-02],\n",
       "                      [-4.6369e-01,  2.0170e-02,  1.9334e-01,  3.2369e-01,  2.5080e-01,\n",
       "                        2.8840e-01,  2.8185e-01, -2.5191e-01,  4.5753e-02, -1.4057e-01],\n",
       "                      [ 1.7144e-01,  1.1247e-01, -9.7213e-02,  2.2747e-01,  4.1978e-01,\n",
       "                        8.5629e-02,  4.1561e-01, -4.3762e-01,  3.6703e-01,  5.6778e-03],\n",
       "                      [-3.6140e-02,  1.3885e-01,  2.6398e-01,  3.6254e-01,  3.5769e-03,\n",
       "                        6.3234e-02, -6.0924e-02, -1.0542e-01,  3.4160e-03, -3.3597e-01],\n",
       "                      [ 1.6559e-03,  4.0637e-01, -4.2230e-01, -1.0064e-02, -5.2923e-02,\n",
       "                       -3.1094e-01, -1.5003e-01, -4.0297e-02, -1.0755e-01,  1.6225e-01],\n",
       "                      [ 2.5332e-01, -1.8630e-01, -1.5215e-01,  3.2567e-01,  1.2525e-01,\n",
       "                       -3.4397e-01, -3.6273e-01,  3.3877e-01, -6.7347e-02,  1.0970e-01],\n",
       "                      [-1.3195e-01, -3.6873e-01, -4.4368e-01,  4.2226e-01, -1.8005e-01,\n",
       "                        2.6933e-01,  5.6069e-01,  8.3614e-01, -1.4568e-01, -5.5002e-01],\n",
       "                      [-7.0800e-02,  1.6251e-01, -1.2990e-01,  5.2100e-02, -1.4480e-02,\n",
       "                       -3.3526e-01, -1.1332e-01,  3.6967e-01, -3.4816e-02,  2.8891e-01],\n",
       "                      [ 4.3783e-01,  3.3301e-01, -9.0785e-02, -1.4373e-01,  3.5533e-01,\n",
       "                       -1.7379e-01, -3.2454e-01,  3.1253e-01, -3.2502e-02, -1.2958e-01],\n",
       "                      [ 4.1152e-02, -3.4778e-01,  1.6425e-01,  5.1139e-02,  2.9677e-01,\n",
       "                       -6.7702e-02,  2.0533e-01,  1.3132e-01,  2.7133e-01, -1.0754e-01],\n",
       "                      [-4.3955e-02, -5.2244e-02,  3.1145e-01,  9.3884e-02, -3.9295e-01,\n",
       "                        1.6863e-01,  7.7764e-02, -1.3855e-01, -1.3593e-01,  4.6964e-01],\n",
       "                      [ 8.2714e-02, -1.5517e-01, -1.3020e+00, -1.1308e-01, -3.6775e-01,\n",
       "                        2.7877e-01,  2.6246e-01,  1.7419e+00, -1.4500e-01, -2.6242e-01],\n",
       "                      [ 3.9452e-01, -2.3220e-01,  6.6025e-02, -3.0098e-02,  4.1327e-01,\n",
       "                        3.3470e-02, -1.4662e-01,  3.0426e-01,  4.0646e-01,  5.1603e-02],\n",
       "                      [ 4.9003e-01,  3.1675e-02, -2.1822e-01, -5.5829e-01,  3.2083e-01,\n",
       "                        1.1394e-01,  7.6757e-02,  1.2964e-01,  1.4818e-02, -1.3926e-01],\n",
       "                      [-1.0374e-01,  1.3359e-01, -4.9660e-01, -1.2703e-01, -1.3414e-02,\n",
       "                        6.6863e-02, -4.7256e-01,  4.4215e-01, -3.6465e-01,  1.8550e-01],\n",
       "                      [ 4.5653e-01,  5.2711e-02, -9.4554e-02, -4.9784e-01, -2.9776e-01,\n",
       "                       -4.2119e-01, -2.5564e-02,  3.3339e-01,  4.5324e-02,  3.3195e-01],\n",
       "                      [-3.5491e-01, -1.4106e-01,  6.5706e-02,  3.1731e-01,  1.0235e-01,\n",
       "                        4.6447e-01,  4.1387e-02, -7.9614e-02,  1.4494e-01, -1.4225e-01],\n",
       "                      [-8.5969e-02, -2.8384e-01,  4.3428e-02,  4.4486e-01,  3.8338e-01,\n",
       "                        6.4311e-02,  3.8236e-01, -1.5318e-01, -1.2332e-01,  2.5924e-02],\n",
       "                      [ 1.1075e-01, -4.1874e-01,  2.8309e-01,  3.9248e-01,  2.7488e-02,\n",
       "                       -8.7654e-02,  3.1014e-01, -1.9046e-01,  2.3019e-02, -2.7292e-01],\n",
       "                      [ 3.4467e-02, -4.5891e-01,  1.5399e-01,  3.5680e-01,  2.4994e-01,\n",
       "                        4.1930e-01,  4.5452e-01, -2.9571e-01,  2.9149e-01, -4.5445e-01],\n",
       "                      [-9.0457e-02, -1.3902e-01,  3.7930e-01,  2.1351e-01,  4.2058e-01,\n",
       "                        1.2210e-01,  4.2712e-01, -3.5777e-01,  2.6655e-01, -4.7321e-01],\n",
       "                      [-3.6872e-03,  1.0042e-01, -3.2634e-01, -2.3340e-01, -1.6555e-01,\n",
       "                       -2.6925e-01, -3.8076e-01,  3.5771e-01, -2.2135e-01,  3.0561e-01],\n",
       "                      [-1.5249e-01, -5.1735e-01,  1.7959e-01,  3.8473e-01,  1.4643e-01,\n",
       "                        1.0506e-02,  4.2980e-01, -4.0346e-01, -2.1759e-03, -2.9233e-02],\n",
       "                      [ 3.2112e-01,  6.7119e-02,  3.7365e-02, -2.0140e-01, -1.3419e-01,\n",
       "                       -1.9384e-01, -4.5000e-01,  4.7501e-02, -3.7217e-01,  2.4517e-01]],\n",
       "                     device='mps:0')),\n",
       "             ('gru.bias_ih_l2',\n",
       "              tensor([ 0.0353,  0.0773,  0.0290, -0.1260, -0.0664,  0.3460, -0.0279,  0.1528,\n",
       "                      -0.0963, -0.0640, -0.7048, -0.9966,  0.7218, -0.7679, -0.1842, -0.6087,\n",
       "                      -0.3732,  0.8194, -0.9290, -0.8720,  0.0710, -0.3034,  0.3840,  0.3073,\n",
       "                      -0.0990,  0.4817,  0.1426, -0.3834, -0.0074, -0.2610], device='mps:0')),\n",
       "             ('gru.bias_hh_l2',\n",
       "              tensor([ 0.2348, -0.1008,  0.1414, -0.4031, -0.0959,  0.0448,  0.1239,  0.0444,\n",
       "                       0.0858, -0.1589, -0.6027, -0.8946,  0.7385, -0.4262, -0.3657, -0.6760,\n",
       "                      -0.4160,  0.6226, -1.0302, -0.9488, -0.3922, -0.2109,  0.3926, -0.1239,\n",
       "                       0.3900,  0.2800,  0.2962, -0.2276,  0.5283, -0.1600], device='mps:0')),\n",
       "             ('gru.weight_ih_l3',\n",
       "              tensor([[-2.4029e-01, -3.5732e-01, -1.4185e-01,  1.2182e-01,  1.3139e-01,\n",
       "                        1.6454e-01,  4.2404e-02,  4.2664e-02,  2.9572e-01, -1.3459e-01],\n",
       "                      [ 1.1531e-03, -2.3758e-01,  1.5389e-01, -5.7204e-02,  3.1850e-02,\n",
       "                        1.9777e-01,  3.1989e-01, -2.4078e-02,  3.5852e-01, -8.3674e-02],\n",
       "                      [ 3.2873e-03,  1.2365e-01,  1.6727e-01,  2.7881e-01,  2.4181e-01,\n",
       "                        1.2956e-01,  3.1196e-01, -3.4607e-01,  3.2844e-01,  1.3726e-01],\n",
       "                      [ 9.1919e-02, -1.0376e-01, -1.7008e-01, -2.1027e-01,  4.7973e-01,\n",
       "                       -2.4674e-01, -2.7932e-01,  8.6071e-02,  1.6633e-02,  1.7822e-01],\n",
       "                      [ 5.2344e-02, -1.5470e-01, -7.6570e-02,  5.6967e-02,  4.8250e-01,\n",
       "                        1.8666e-01,  4.0264e-01, -8.9744e-02,  3.6455e-01, -4.9523e-01],\n",
       "                      [ 3.5642e-01,  3.3908e-01, -2.6738e-01, -4.1978e-01, -3.4492e-01,\n",
       "                       -1.5961e-01, -2.8863e-01,  4.7795e-02, -3.7257e-02,  2.6414e-01],\n",
       "                      [-2.3007e-01, -4.0258e-01,  3.6700e-01, -4.3665e-02,  2.7563e-01,\n",
       "                        2.8880e-02,  3.3651e-01, -9.1509e-02,  4.8830e-01, -3.7752e-01],\n",
       "                      [-1.9646e-01,  5.0426e-02, -7.7003e-02,  5.6283e-01,  3.5425e-01,\n",
       "                        2.3792e-01,  4.0354e-01, -3.3211e-01,  1.7326e-01, -2.8956e-01],\n",
       "                      [-2.2703e-01, -3.9601e-01,  1.5103e-01, -1.1199e-02,  3.9134e-01,\n",
       "                        3.3866e-01,  3.4739e-01, -4.1453e-01,  4.9888e-01, -3.1202e-01],\n",
       "                      [-2.1217e-01, -2.2929e-02,  3.7565e-01,  1.5984e-01,  3.8386e-01,\n",
       "                        4.2328e-01,  4.0014e-01, -1.0471e-01,  1.7189e-01, -4.1910e-01],\n",
       "                      [ 5.4622e-01,  7.7641e-01, -5.2686e-01, -1.0591e-02, -5.5822e-01,\n",
       "                       -4.7711e-01, -5.8964e-01,  1.4302e-01, -2.1247e-01,  4.6158e-02],\n",
       "                      [ 5.2886e-01,  3.7846e-01, -3.0204e-01, -9.0159e-01, -5.6457e-01,\n",
       "                       -2.9479e-01, -5.8504e-01, -7.0352e-02, -5.1264e-01,  3.7825e-01],\n",
       "                      [ 5.5308e-01,  7.8533e-01, -2.1359e-01, -3.1684e-01, -4.9601e-01,\n",
       "                       -7.2223e-01, -2.6193e-01,  1.1468e-01, -4.6368e-01,  4.1842e-01],\n",
       "                      [ 1.8467e-01,  6.5690e-01, -1.3497e-01, -5.4055e-01, -6.8959e-01,\n",
       "                       -4.9639e-01, -5.5229e-01,  4.9605e-01, -1.3027e-01,  7.2514e-01],\n",
       "                      [ 6.4976e-01,  6.3086e-01, -1.6008e-01, -3.4446e-01, -1.5650e-01,\n",
       "                       -6.9394e-01, -5.6673e-01,  9.8633e-02, -3.7535e-01,  3.6007e-01],\n",
       "                      [-7.0907e-01, -9.1077e-01, -9.8499e-01,  8.7136e-01,  1.0132e+00,\n",
       "                        9.1668e-01,  4.4816e-01,  2.7274e+00,  1.0623e+00, -1.0378e+00],\n",
       "                      [ 5.8579e-01,  1.0441e+00, -2.5469e-01, -6.9864e-02, -4.0652e-01,\n",
       "                       -5.4899e-01, -6.3584e-01,  1.9461e-01, -2.6986e-01,  2.9436e-01],\n",
       "                      [-8.7515e-01, -1.3245e+00, -5.8190e-01,  5.1584e-01,  5.9027e-01,\n",
       "                        1.4557e+00,  8.4623e-01,  2.7017e+00,  7.6696e-01, -7.8733e-01],\n",
       "                      [ 6.1220e-01,  8.4747e-01, -4.7952e-01, -5.0498e-01, -4.3592e-01,\n",
       "                       -3.5420e-01, -6.9114e-01,  4.2119e-01, -8.2538e-01,  6.1308e-01],\n",
       "                      [ 4.0378e-01,  7.3008e-01, -1.1802e-02, -5.0616e-02, -6.6231e-01,\n",
       "                       -5.2693e-01, -6.9704e-01,  1.1313e-01, -6.0087e-01,  5.4961e-01],\n",
       "                      [-1.2255e-01, -9.2513e-02, -8.6952e-02,  8.0575e-02, -2.0379e-01,\n",
       "                       -1.1374e-01, -1.8148e-01,  3.4805e-01, -4.9403e-01,  2.8495e-01],\n",
       "                      [-3.4765e-01, -4.3968e-02,  2.5398e-01,  4.1002e-01,  2.4457e-01,\n",
       "                        4.2495e-01,  1.6403e-01, -4.0572e-01,  2.4604e-01, -2.1887e-01],\n",
       "                      [ 1.6252e-01,  7.2436e-02,  1.0245e-01, -1.9793e-01, -2.9621e-01,\n",
       "                       -5.0152e-01, -4.0553e-01,  5.1467e-01, -4.0674e-01,  1.7630e-01],\n",
       "                      [-4.8284e-01, -3.8123e-01,  2.4962e-01,  2.2402e-01,  3.7447e-01,\n",
       "                       -1.2021e-01,  3.9626e-01, -2.9895e-02, -2.9100e-02, -3.5066e-01],\n",
       "                      [ 2.5552e-01,  3.2720e-01, -8.6847e-02, -2.1430e-01, -1.1829e-01,\n",
       "                       -4.1170e-01, -3.1104e-01,  3.5159e-01, -4.5635e-01,  1.6950e-01],\n",
       "                      [ 6.8886e-01,  2.6636e-01, -4.5246e-01, -3.6724e-01, -7.5402e-01,\n",
       "                       -1.5147e-01, -2.8717e-01,  3.4917e-01, -4.9525e-02,  1.1689e-01],\n",
       "                      [-2.2994e-01, -2.0284e-01,  3.2528e-01, -2.1112e-02,  2.4695e-01,\n",
       "                        3.6423e-01,  5.4794e-02, -1.4880e-01,  1.3276e-01, -9.7356e-02],\n",
       "                      [ 3.1759e-02,  2.1435e-01, -1.6419e-01,  2.1684e-02, -5.2255e-01,\n",
       "                        2.5795e-01, -2.3820e-01,  2.4214e-01,  7.1265e-03,  1.4048e-01],\n",
       "                      [-4.3651e-01, -4.2857e-01,  5.4943e-01,  4.4557e-01,  1.9222e-01,\n",
       "                        3.8911e-01,  5.4896e-01, -1.3321e-03,  2.3536e-01, -4.5015e-01],\n",
       "                      [ 1.5332e-01, -4.8487e-02,  1.9585e-01,  3.4638e-01,  3.2771e-01,\n",
       "                        5.1868e-01, -3.3475e-02, -3.0833e-01,  1.2266e-01, -4.2655e-01]],\n",
       "                     device='mps:0')),\n",
       "             ('gru.weight_hh_l3',\n",
       "              tensor([[ 2.0004e-02,  4.0569e-01, -4.0004e-01,  2.5047e-01, -3.0613e-01,\n",
       "                       -2.9673e-02, -2.1721e-01, -3.2797e-01,  2.2776e-01,  7.7291e-02],\n",
       "                      [-4.0337e-01, -1.1881e-02, -2.3040e-01,  3.5680e-01, -1.9300e-01,\n",
       "                        3.7197e-01,  3.9187e-01, -1.1103e-02,  1.4889e-01,  4.1950e-01],\n",
       "                      [-4.6551e-01,  2.6843e-01, -1.3925e-01,  5.0413e-01,  1.4809e-01,\n",
       "                        2.9017e-01,  1.2217e-01,  2.1070e-01,  4.9824e-02, -1.3481e-01],\n",
       "                      [-2.6023e-01, -2.4747e-01,  2.3650e-01,  2.8535e-01,  5.6774e-02,\n",
       "                       -3.3561e-02,  4.9028e-01,  1.3029e-01, -3.7437e-01, -3.4928e-02],\n",
       "                      [-2.3420e-01, -7.6846e-02, -4.4661e-01,  1.6683e-01, -3.2888e-01,\n",
       "                        1.1857e-01, -4.0799e-02, -1.2621e-01,  6.4398e-02,  1.0858e-02],\n",
       "                      [ 3.6064e-01, -3.1341e-01,  4.6170e-01,  4.9597e-02,  1.4975e-01,\n",
       "                       -4.4250e-01,  1.6933e-01, -1.2659e-01, -4.2278e-01, -4.0391e-01],\n",
       "                      [ 3.7737e-02,  6.4682e-02,  2.5306e-02,  1.5687e-01, -1.3795e-01,\n",
       "                        1.3670e-01,  3.7697e-01, -1.0615e-01,  2.2051e-01,  2.9077e-01],\n",
       "                      [-8.8498e-03,  1.1727e-01, -4.8867e-02,  3.7403e-01, -1.0654e-01,\n",
       "                       -2.4541e-01,  4.8790e-01, -7.8928e-02, -1.9638e-01,  2.2873e-01],\n",
       "                      [-2.0971e-01,  6.3412e-02,  9.1347e-02,  1.5462e-01, -9.4119e-02,\n",
       "                        4.9884e-01,  1.1877e-01, -1.8040e-01, -6.7915e-02,  2.7324e-01],\n",
       "                      [-4.1061e-01, -3.0972e-02, -2.8519e-01,  8.7017e-02, -1.8689e-01,\n",
       "                        4.4371e-01,  3.5010e-01, -9.5673e-02, -4.8740e-02,  2.3807e-01],\n",
       "                      [ 5.8759e-02, -4.4780e-01,  7.3055e-02,  2.0077e-01, -1.9019e-01,\n",
       "                       -3.8478e-02,  1.6311e-01,  1.4691e-02,  6.4992e-02, -4.7743e-01],\n",
       "                      [ 1.9767e-01, -1.1170e-01,  2.6135e-01, -1.6464e-01,  3.1602e-01,\n",
       "                       -3.1038e-01, -2.0995e-01,  1.8626e-01, -7.2262e-02,  7.8743e-02],\n",
       "                      [ 3.5069e-02, -3.6327e-02, -2.2436e-03, -2.9490e-03,  9.0865e-02,\n",
       "                       -4.2889e-01, -5.8494e-01,  2.5971e-01, -3.6720e-01, -2.1395e-01],\n",
       "                      [ 3.2808e-01, -3.6239e-02,  3.3147e-01,  8.3745e-02, -2.2278e-01,\n",
       "                        8.3606e-02,  1.6675e-02,  1.3644e-01, -1.1202e-01, -3.6698e-01],\n",
       "                      [-2.7208e-01, -1.2627e-01, -3.0725e-01, -2.6268e-02,  3.5706e-01,\n",
       "                        6.8267e-02, -1.7288e-02, -1.8332e-01, -2.6889e-01, -6.2572e-02],\n",
       "                      [ 1.3407e-01,  3.3596e-01, -1.2096e-01,  5.2867e-01,  1.5349e-01,\n",
       "                        2.9198e+00,  2.2366e-01,  2.7517e+00, -1.8070e-01,  6.5186e-02],\n",
       "                      [ 5.0972e-01,  5.5624e-02,  3.9967e-01,  2.4287e-01,  1.5497e-01,\n",
       "                       -3.2801e-01,  2.3249e-01,  2.7305e-01, -6.0893e-02,  7.9063e-02],\n",
       "                      [-3.5818e-01,  2.8324e-01, -6.7523e-01,  1.6165e-01, -3.3732e-01,\n",
       "                        2.4519e+00, -1.9264e-01,  2.8440e+00,  3.1956e-01,  6.9631e-01],\n",
       "                      [ 2.2161e-01, -2.0577e-01,  4.4409e-01, -4.4132e-02, -3.4782e-01,\n",
       "                       -3.1897e-01, -1.4376e-01,  4.0816e-01, -2.5091e-03, -3.1364e-01],\n",
       "                      [ 3.4068e-02, -2.9090e-01,  4.0093e-01, -3.0280e-01,  3.8458e-01,\n",
       "                       -1.3552e-01,  1.4849e-01,  2.1799e-01, -5.7685e-01, -5.6190e-02],\n",
       "                      [ 4.1545e-01,  4.6094e-02,  7.0204e-02,  1.3255e-01,  2.7556e-01,\n",
       "                       -1.4406e-01, -3.0840e-02, -1.7916e-01, -4.5147e-01, -1.5260e-02],\n",
       "                      [-4.4594e-01, -8.0984e-02,  8.9558e-02,  1.3712e-01, -3.6256e-01,\n",
       "                        5.0506e-01,  2.4806e-01, -2.3570e-01,  4.9463e-01,  4.3314e-02],\n",
       "                      [ 3.9095e-01, -1.8017e-02,  4.9249e-01, -7.1198e-02,  4.4207e-01,\n",
       "                       -2.1731e-01,  7.2970e-02, -1.3196e-01, -3.1165e-01,  5.4372e-03],\n",
       "                      [ 3.4836e-02,  4.1901e-01,  1.0947e-01,  2.0737e-01, -2.9788e-01,\n",
       "                        1.7908e-01, -5.2297e-03,  1.6304e-01, -9.9231e-02,  1.1427e-01],\n",
       "                      [ 2.9335e-01, -3.0546e-01,  4.8491e-01, -2.7050e-01,  4.9655e-02,\n",
       "                       -6.9045e-02,  1.3872e-01,  2.5258e-01, -3.1219e-01, -3.3149e-01],\n",
       "                      [ 2.7242e-01, -2.3384e-01,  2.1368e-01, -1.3815e-01, -1.9909e-01,\n",
       "                        3.9136e-01, -2.4776e-01, -3.0119e-01,  7.9777e-02,  2.8523e-01],\n",
       "                      [-4.8309e-01, -3.6221e-02,  6.7787e-02, -3.2821e-02, -2.8579e-01,\n",
       "                        2.4436e-01,  2.2230e-01,  1.7864e-01,  3.6981e-01,  3.6255e-01],\n",
       "                      [-3.0510e-02,  8.4182e-02,  6.0828e-02, -7.6233e-01,  3.1624e-01,\n",
       "                        5.4165e-01, -7.5683e-01,  1.4825e-01, -1.4373e-01, -1.4858e-01],\n",
       "                      [-3.9284e-01, -6.6792e-02, -3.7149e-01,  6.4168e-03,  2.2266e-02,\n",
       "                        2.3462e-01,  2.4352e-02,  6.7176e-03,  2.9587e-01,  2.3835e-02],\n",
       "                      [-4.8091e-01,  4.7313e-01,  5.9540e-02,  1.7707e-01, -3.1935e-01,\n",
       "                        1.5421e-01,  1.3286e-01, -3.6377e-01,  4.5173e-01,  3.2457e-01]],\n",
       "                     device='mps:0')),\n",
       "             ('gru.bias_ih_l3',\n",
       "              tensor([ 0.1457,  0.2908, -0.1690,  0.0833,  0.3218, -0.1467,  0.1492,  0.1818,\n",
       "                       0.0604,  0.1590, -0.5911, -0.1984, -0.1836, -0.3286, -0.2062,  1.1409,\n",
       "                      -0.3783,  1.1220, -0.6643, -0.5475, -0.2789,  0.1906, -0.4118,  0.2292,\n",
       "                      -0.0026, -0.2571, -0.1360, -0.1266,  0.3861,  0.5202], device='mps:0')),\n",
       "             ('gru.bias_hh_l3',\n",
       "              tensor([ 0.4380,  0.0365, -0.1074, -0.1109,  0.0196, -0.2835,  0.3800,  0.3235,\n",
       "                       0.0911,  0.0497, -0.5362, -0.4761, -0.3620, -0.2687, -0.4399,  0.6590,\n",
       "                      -0.4009,  1.1715, -0.2180, -0.2217, -0.3036,  0.4430, -0.0654,  0.3486,\n",
       "                      -0.0311, -0.1829,  0.1895, -0.1645,  0.3264,  0.2909], device='mps:0')),\n",
       "             ('gru.weight_ih_l4',\n",
       "              tensor([[-0.2414, -0.0966, -0.2724,  0.3824,  0.0469,  0.4638,  0.3290,  0.0972,\n",
       "                        0.5078, -0.0979],\n",
       "                      [-0.3161, -0.2285, -0.2059,  0.0881, -0.3690, -0.0206,  0.2471,  0.2417,\n",
       "                       -0.0911,  0.0750],\n",
       "                      [ 0.5452, -0.0408, -0.0143, -0.4751,  0.1927,  0.0797, -0.0143,  0.5235,\n",
       "                       -0.0748, -0.5253],\n",
       "                      [ 0.1406,  0.1079,  0.1772,  0.4198, -0.1843, -0.1502,  0.5777, -0.0164,\n",
       "                       -0.1130,  0.0805],\n",
       "                      [-0.1160, -0.0476, -0.4016,  0.4420, -0.0775,  0.0933,  0.1625, -0.1392,\n",
       "                        0.3846,  0.5536],\n",
       "                      [ 0.2061, -0.4704,  0.2248, -0.1279, -0.1406,  0.1735,  0.0289,  0.4892,\n",
       "                       -0.2553, -0.2949],\n",
       "                      [-0.1708,  0.0082, -0.1812, -0.0317, -0.3666,  0.5428,  0.2872, -0.0613,\n",
       "                        0.0587,  0.1886],\n",
       "                      [-0.0606, -0.0254, -0.0249,  0.1119, -0.1424, -0.1137,  0.0424, -0.3484,\n",
       "                        0.1784,  0.3523],\n",
       "                      [ 0.1086, -0.2134,  0.5342, -0.4912,  0.2985,  0.2154, -0.3325,  0.2466,\n",
       "                       -0.4553, -0.2872],\n",
       "                      [-0.2022,  0.0084, -0.3179,  0.1451, -0.1690,  0.4008,  0.4681, -0.1460,\n",
       "                        0.3616, -0.0911],\n",
       "                      [ 0.3915, -0.5343,  0.5339, -0.9433,  0.5081, -0.4234, -0.9177,  0.3962,\n",
       "                       -0.3196, -0.3950],\n",
       "                      [ 0.3255, -0.5619,  0.9873, -1.1265,  0.9230, -0.1852, -0.8865,  0.5458,\n",
       "                       -0.7741, -0.6400],\n",
       "                      [ 0.8726, -0.8187,  0.7645, -0.5096,  0.7631, -0.0271, -0.9234,  0.6814,\n",
       "                       -0.9672, -0.7407],\n",
       "                      [-0.1639,  0.5807, -0.5797,  0.7937, -0.4304, -0.4714,  0.4932,  0.1737,\n",
       "                        0.3498, -0.0414],\n",
       "                      [ 0.9907, -0.9152,  0.9530, -0.5103,  0.9482, -0.1680, -0.7237,  0.2169,\n",
       "                       -0.8030, -0.8653],\n",
       "                      [-0.7387,  0.8810, -0.6255,  0.4478, -0.1107,  0.0476,  0.3202, -0.1274,\n",
       "                        0.9946,  0.4774],\n",
       "                      [ 0.9951, -0.5667,  0.9052, -0.7396,  0.6308,  0.2969, -0.8426, -0.0237,\n",
       "                       -0.4074, -0.7994],\n",
       "                      [-0.7191,  0.5567, -0.7460,  0.8455, -0.7285, -0.4278,  0.8165, -0.0374,\n",
       "                        0.6801,  0.2696],\n",
       "                      [ 0.7354, -0.2064,  0.5478, -0.2527,  0.1362,  0.1299, -0.5152,  0.5593,\n",
       "                       -0.1337, -0.7230],\n",
       "                      [ 0.9772, -0.5121,  0.6838, -0.8583,  1.0012, -0.2372, -0.7409, -0.2729,\n",
       "                       -0.7169, -0.4496],\n",
       "                      [ 0.3875, -0.3604,  0.1775, -0.2373,  0.0124,  0.0197, -0.2621,  0.1548,\n",
       "                       -0.4999, -0.3557],\n",
       "                      [-0.2681,  0.2977, -0.0507,  0.2779, -0.4632,  0.2352, -0.0125, -0.1946,\n",
       "                        0.5677,  0.3605],\n",
       "                      [-0.3089,  0.3752, -0.4852,  0.3131, -0.0495,  0.5724,  0.3168, -0.0264,\n",
       "                        0.1427,  0.0904],\n",
       "                      [-0.2307,  0.3982, -0.4533,  0.3780, -0.5189,  0.0336,  0.1797, -0.2773,\n",
       "                       -0.0087,  0.4724],\n",
       "                      [ 0.2689, -0.3351,  0.5360, -0.2817,  0.1433, -0.5049, -0.3424,  0.1743,\n",
       "                       -0.3458, -0.1552],\n",
       "                      [-0.3611,  0.2597, -0.2231,  0.0055, -0.3873,  0.3116,  0.0602, -0.0434,\n",
       "                        0.5766,  0.4329],\n",
       "                      [ 0.2813, -0.3060,  0.1646, -0.1489,  0.4399, -0.1429, -0.2074, -0.0074,\n",
       "                       -0.1050, -0.2132],\n",
       "                      [ 0.0231,  0.2817, -0.2877,  0.1951, -0.3061, -0.0916,  0.1287, -0.0236,\n",
       "                        0.4883,  0.3171],\n",
       "                      [ 0.0705,  0.0488,  0.0610, -0.4044,  0.2555, -1.5480, -0.1898, -2.0494,\n",
       "                       -0.4143, -0.0084],\n",
       "                      [ 0.1379, -0.4526,  0.4881, -0.2127,  0.3492,  0.0427, -0.2534,  0.4096,\n",
       "                        0.0379, -0.4646]], device='mps:0')),\n",
       "             ('gru.weight_hh_l4',\n",
       "              tensor([[ 8.7558e-02,  3.5237e-01,  2.4669e-01,  4.5145e-01, -4.7194e-01,\n",
       "                        3.7358e-01, -2.4656e-02,  2.4024e-01,  7.7812e-02, -1.0570e-01],\n",
       "                      [ 2.2463e-01, -2.2534e-01,  6.0081e-02,  3.2006e-01, -4.6006e-02,\n",
       "                        2.1023e-01, -3.1835e-01,  8.0771e-02, -1.0037e-01, -2.2347e-02],\n",
       "                      [ 4.6361e-01,  2.0221e-02, -2.8507e-01, -3.3582e-01,  9.8910e-02,\n",
       "                        5.2642e-03,  5.4169e-01, -5.9620e-01,  2.3971e-03,  4.5523e-01],\n",
       "                      [-1.2564e-01,  7.0084e-02, -1.6303e-01, -1.0220e-01, -3.1246e-01,\n",
       "                        2.2015e-01, -3.7929e-01,  2.7517e-01, -3.9471e-01, -1.9263e-01],\n",
       "                      [-2.2999e-01,  4.7332e-02,  6.8799e-02,  1.9948e-01, -8.0015e-02,\n",
       "                        5.3944e-01,  6.5554e-02,  6.2055e-01, -1.8751e-01,  5.7608e-02],\n",
       "                      [ 3.7495e-01, -3.2712e-01, -2.6144e-01, -7.1796e-02,  3.3457e-01,\n",
       "                       -1.2491e-01,  2.7050e-01, -4.8408e-01,  1.4741e-01,  2.1823e-01],\n",
       "                      [ 8.7724e-02,  4.0140e-02,  3.8221e-01,  2.2351e-01, -1.5473e-01,\n",
       "                        1.4910e-03, -3.6442e-01,  3.7864e-02,  2.3353e-02,  3.2968e-02],\n",
       "                      [-4.2218e-01, -4.6769e-02,  4.5725e-02,  4.8764e-01, -2.6571e-01,\n",
       "                        2.9834e-01,  7.2042e-02, -5.4263e-02,  5.2992e-02, -1.4962e-01],\n",
       "                      [ 6.1196e-01, -1.7286e-01, -2.2717e-01, -1.9703e-01,  3.7596e-01,\n",
       "                       -3.3995e-01,  6.6027e-01, -1.6643e-02,  1.2561e-01,  1.3934e-01],\n",
       "                      [-4.3597e-02, -1.3770e-02,  4.1443e-01,  4.5321e-01, -8.9013e-02,\n",
       "                        4.3211e-01, -3.6806e-01,  2.7033e-01, -4.4504e-01,  8.4247e-02],\n",
       "                      [ 6.0387e-02, -2.7961e-01, -8.0148e-02, -4.9031e-01,  5.3106e-01,\n",
       "                       -3.4521e-01,  4.0115e-01, -8.9420e-02,  5.0807e-01,  1.8749e-01],\n",
       "                      [ 3.5752e-01, -5.9364e-01, -8.1121e-02, -5.1587e-01,  1.8248e-01,\n",
       "                       -6.0369e-01,  4.8818e-01,  3.3534e-01,  5.6321e-02,  3.5646e-01],\n",
       "                      [ 2.2978e-01, -2.0648e-02, -1.1460e-01, -5.3852e-01,  5.1241e-01,\n",
       "                        2.5952e-03,  4.9870e-02, -2.0853e-01,  2.9333e-01,  2.5141e-01],\n",
       "                      [ 1.3942e+00, -1.1459e+00, -8.7545e-01, -4.1028e-01,  1.3673e+00,\n",
       "                       -1.3232e-01,  1.3697e+00, -6.5201e-01,  1.5727e+00,  9.6904e-01],\n",
       "                      [ 1.6986e-01, -3.2986e-01, -5.6772e-01, -5.9364e-01,  1.3846e-01,\n",
       "                       -2.0810e-01,  3.3775e-01, -4.6691e-01,  5.6184e-01, -2.5907e-02],\n",
       "                      [ 1.3277e+00, -1.6883e+00, -1.8206e+00, -1.3090e+00,  1.6625e+00,\n",
       "                       -2.8105e-01,  1.7701e+00, -7.0457e-01,  1.7838e+00,  1.5628e+00],\n",
       "                      [-1.7794e-01,  4.9553e-02,  1.3521e-01,  7.8901e-02,  3.1761e-01,\n",
       "                       -1.7428e-01,  2.4271e-01, -2.2901e-01,  1.0249e-01,  4.4059e-01],\n",
       "                      [ 1.4811e+00, -1.8774e+00, -1.9998e+00, -1.2089e+00,  1.7486e+00,\n",
       "                       -4.9799e-01,  1.7677e+00, -8.1965e-01,  1.8713e+00,  1.8272e+00],\n",
       "                      [ 4.0944e-01, -3.1142e-01, -2.6933e-01, -7.0353e-02,  3.1527e-01,\n",
       "                        4.0908e-02,  2.8032e-01, -3.2081e-01,  1.4464e-01,  1.1136e-01],\n",
       "                      [ 4.7211e-01, -3.2863e-01, -3.8460e-01, -3.8978e-01,  5.2423e-01,\n",
       "                       -4.5853e-02,  4.0539e-01, -5.7051e-01,  2.0552e-01,  4.6274e-01],\n",
       "                      [ 6.2260e-02, -7.0375e-02, -1.7667e-01, -2.7986e-01,  4.3846e-01,\n",
       "                        1.8634e-02,  2.7856e-01, -5.8490e-01,  8.4538e-02,  4.2951e-01],\n",
       "                      [-8.7311e-02,  5.8281e-02, -3.2913e-03,  4.7259e-04, -3.7942e-01,\n",
       "                        1.0864e-01, -2.4298e-01,  4.7062e-01, -2.7682e-01, -5.1834e-01],\n",
       "                      [ 1.3511e-02,  4.8827e-01, -1.5093e-02,  5.5052e-02, -2.1467e-01,\n",
       "                       -1.1742e-01,  3.3646e-02, -3.8618e-02, -2.1960e-01, -3.3913e-01],\n",
       "                      [-3.8791e-01,  5.7101e-03,  1.1806e-01,  4.9239e-01, -2.3464e-01,\n",
       "                        4.8332e-02,  3.3004e-02,  1.2624e-01, -3.5960e-01, -4.9244e-02],\n",
       "                      [ 4.8305e-01, -2.7494e-01, -2.3636e-01, -6.9676e-02,  8.5373e-02,\n",
       "                        5.0084e-02, -5.1392e-02,  1.6824e-03,  1.7789e-01,  3.3810e-01],\n",
       "                      [-2.1855e-01, -7.5065e-02,  5.4169e-01,  4.1491e-01, -9.0052e-03,\n",
       "                        1.0326e-01, -1.8901e-01,  1.9633e-01, -3.3104e-01, -2.3300e-01],\n",
       "                      [ 1.2871e-01,  7.4456e-03, -3.3251e-01, -3.3380e-01,  4.1158e-01,\n",
       "                       -3.3323e-01,  1.3038e-01, -2.6789e-02, -3.2280e-02,  4.8067e-01],\n",
       "                      [-4.7797e-01,  2.1203e-01,  5.5328e-02,  1.5627e-01,  5.3442e-02,\n",
       "                        4.3092e-01, -4.5985e-01,  6.0566e-02, -4.1585e-01, -3.6999e-01],\n",
       "                      [-1.5331e-01, -4.3680e-01,  1.4899e-01, -4.1915e-01,  1.3607e-01,\n",
       "                        1.3542e-01,  8.3169e-03,  2.5902e-01, -1.6405e-01, -9.6039e-02],\n",
       "                      [ 2.1573e-01, -3.5683e-01, -1.3617e-01, -2.3239e-01,  2.5685e-01,\n",
       "                       -2.7626e-01,  4.1510e-01, -6.6684e-02,  3.6431e-01, -5.8553e-02]],\n",
       "                     device='mps:0')),\n",
       "             ('gru.bias_ih_l4',\n",
       "              tensor([ 0.1145,  0.0119, -0.3415,  0.0585,  0.5588, -0.3307, -0.0925,  0.0895,\n",
       "                      -0.1521,  0.4691, -0.0875, -0.7235, -0.9691,  0.0316, -0.7449,  0.6402,\n",
       "                      -0.2736,  0.5745, -0.1546, -0.5188, -0.2889,  0.4986,  0.4144,  0.3200,\n",
       "                      -0.1371,  0.5199, -0.4873, -0.0550, -0.4909, -0.1216], device='mps:0')),\n",
       "             ('gru.bias_hh_l4',\n",
       "              tensor([ 0.3997,  0.0775, -0.1984,  0.1168,  0.2108,  0.0841, -0.0513,  0.0014,\n",
       "                      -0.5634, -0.0674, -0.3706, -0.7661, -0.3921, -0.0678, -0.3658,  0.8966,\n",
       "                      -0.3667,  0.4553, -0.4675, -0.4930, -0.4359,  0.3265,  0.2979,  0.3116,\n",
       "                      -0.3785, -0.0671, -0.2897,  0.0522, -0.4245, -0.3333], device='mps:0')),\n",
       "             ('decoder.weight',\n",
       "              tensor([[ 2.8119e-01, -1.8552e-01, -1.3979e-01,  ...,  3.6298e-02,\n",
       "                        3.7737e-01,  2.6694e-01],\n",
       "                      [-2.7731e-01,  2.2271e-01, -1.1082e-02,  ..., -1.1063e-01,\n",
       "                        1.2917e-01, -5.1069e-01],\n",
       "                      [ 2.3788e-01, -5.1775e-01,  5.0953e-04,  ..., -8.7018e-02,\n",
       "                        7.7233e-01, -6.3769e-02],\n",
       "                      ...,\n",
       "                      [ 2.4057e-01,  1.7730e-01,  1.6504e-01,  ..., -3.2763e-01,\n",
       "                        6.6471e-01, -3.2903e-01],\n",
       "                      [-1.5910e-01, -5.8789e-02, -1.0615e-01,  ...,  2.5592e-02,\n",
       "                        5.8882e-01, -8.9912e-02],\n",
       "                      [-1.0805e-02, -4.0929e-01, -1.2112e-01,  ...,  1.6721e-01,\n",
       "                        8.4416e-01,  3.6024e-01]], device='mps:0')),\n",
       "             ('decoder.bias',\n",
       "              tensor([-0.3002,  0.2248,  0.0235,  ..., -0.1810, -0.0943, -0.3343],\n",
       "                     device='mps:0'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('decoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da872055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
