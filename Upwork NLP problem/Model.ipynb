{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32602976",
   "metadata": {},
   "source": [
    "### PyTorch model for text generation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a322d0",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5161c5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x17c3d7a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import string\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f3cca7",
   "metadata": {},
   "source": [
    "**Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6fe666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading, preparation\n",
    "\n",
    "data = pd.read_csv('Shakespeare_data.csv')\n",
    "data = data.rename(columns={'PlayerLine': 'text'})\n",
    "\n",
    "data = data['text']\n",
    "length = len(data)\n",
    "#print(f\"There are {length} sentences in dataset.\", '\\n')\n",
    "data.head()\n",
    "\n",
    "text = list(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae1a19",
   "metadata": {},
   "source": [
    "**GPU checking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655bc140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is found and connected!\n"
     ]
    }
   ],
   "source": [
    "# Device Selection\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"GPU is found and connected!\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.cuda.device(0)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU, will do training with CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e97631",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60a8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "\n",
    "batch_size = 16\n",
    "seq_size = 32\n",
    "embedding_size = 64\n",
    "lstm_size = 64\n",
    "gradients_norm = 5\n",
    "\n",
    "\n",
    "# Define function to join all sentences into one long sentence\n",
    "def joinStrings(text):\n",
    "    return ' '.join(string for string in text)\n",
    "text = joinStrings(text)\n",
    "\n",
    "\n",
    "# Get list of words from document\n",
    "def doc2words(doc):\n",
    "    lines = doc.split('\\n')\n",
    "    lines = [line.strip(r'\\\"') for line in lines]\n",
    "    words = ' '.join(lines).split()\n",
    "    return words\n",
    "\n",
    "# Remove punctuations\n",
    "def removepunct(words):\n",
    "    punct = set(string.punctuation)\n",
    "    words = [''.join([char for char in list(word) if char not in punct]) for word in words]\n",
    "    return words\n",
    "\n",
    "# Create a vocabulary where words are ordered by their frequency of occurrence\n",
    "def getvocab(words):\n",
    "    wordfreq = Counter(words)\n",
    "    sorted_wordfreq = sorted(wordfreq, key=wordfreq.get)\n",
    "    return sorted_wordfreq\n",
    "\n",
    "# Get dictionary of int to words and word to int\n",
    "def vocab_map(vocab):\n",
    "    int_to_vocab = {k:w for k,w in enumerate(vocab)}\n",
    "    vocab_to_int = {w:k for k,w in int_to_vocab.items()}\n",
    "    return int_to_vocab, vocab_to_int\n",
    "\n",
    "# Text Preprocessing\n",
    "words = removepunct(doc2words(text))\n",
    "vocab = getvocab(words)\n",
    "int_to_vocab, vocab_to_int = vocab_map(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378605f",
   "metadata": {},
   "source": [
    "**Define batches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96483a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generating batches \n",
    "\n",
    "def get_batches(words, vocab_to_int, batch_size, seq_size):\n",
    "    # Generate a Xs and Ys of shape (batchsize * num_batches) * seq_size\n",
    "    word_ints = [vocab_to_int[word] for word in words]\n",
    "    # Determine Number of Batches\n",
    "    num_batches = int(len(word_ints) / (batch_size * seq_size))\n",
    "    # Prepare Input and Target Sequences\n",
    "    Xs = word_ints[:num_batches*batch_size*seq_size]\n",
    "    Ys = np.zeros_like(Xs)\n",
    "    Ys[:-1] = Xs[1:]\n",
    "    Ys[-1] = Xs[0]\n",
    "    Xs = np.reshape(Xs, (num_batches*batch_size, seq_size))\n",
    "    Ys= np.reshape(Ys, (num_batches*batch_size, seq_size))\n",
    "    \n",
    "    # Batch Generation\n",
    "    for i in range(0, num_batches*batch_size, batch_size):\n",
    "        yield Xs[i:i+batch_size, :], Ys[i:i+batch_size, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210f32c",
   "metadata": {},
   "source": [
    "**Define RNN model and Loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1fab887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch module named RNNModule        \n",
    "        \n",
    "class RNNModule(nn.Module):\n",
    "    # initialize RNN module\n",
    "    def __init__(self, n_vocab, seq_size=32, embedding_size=64, lstm_size=64):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),torch.zeros(1, batch_size, self.lstm_size))\n",
    "    \n",
    "    \n",
    "# Loss function and the optimization algorithm for training a neural network model     \n",
    "    \n",
    "def get_loss_and_train_op(net, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5004a61",
   "metadata": {},
   "source": [
    "**Train Model**\n",
    "\n",
    "*Note:* As I already trained the model, now we do not need to train the model again, we just nead to load the saved model and test it. However, if you want to train the model with larger epochs for some reason to get better results please uncomment below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb31d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train an RNN-based text generation model using the specified data and hyperparameters. \n",
    "# # The training loop performs backpropagation and updates the model's parameters to minimize the loss. \n",
    "    \n",
    "# def train_rnn(words, vocab_to_int, int_to_vocab, n_vocab):\n",
    "    \n",
    "#     # RNN instance\n",
    "#     net = RNNModule(n_vocab, seq_size, embedding_size, lstm_size)\n",
    "#     net = net.to(device)\n",
    "#     criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
    "\n",
    "#     iteration = 0\n",
    "    \n",
    "#     for e in range(10):\n",
    "#         batches = get_batches(words, vocab_to_int, batch_size, seq_size)\n",
    "#         state_h, state_c = net.zero_state(batch_size)\n",
    "\n",
    "#         # Transfer data to GPU\n",
    "#         state_h = state_h.to(device)\n",
    "#         state_c = state_c.to(device)\n",
    "#         for x, y in batches:\n",
    "#             iteration += 1\n",
    "\n",
    "#             # Tell it we are in training mode\n",
    "#             net.train()\n",
    "\n",
    "#             # Reset all gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Transfer data to GPU\n",
    "#             x = torch.tensor(x).to(device)\n",
    "#             y = torch.tensor(y).to(device)\n",
    "\n",
    "#             logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "#             loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "#             state_h = state_h.detach()\n",
    "#             state_c = state_c.detach()\n",
    "\n",
    "#             loss_value = loss.item()\n",
    "\n",
    "#             # Perform back-propagation\n",
    "#             loss.backward(retain_graph=True)\n",
    "\n",
    "#             _ = torch.nn.utils.clip_grad_norm_(net.parameters(), gradients_norm)\n",
    "            \n",
    "#             # Update the network's parameters\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if iteration % 100 == 0:\n",
    "#                 print('Epoch: {}/{}'.format(e, 10),'Iteration: {}'.format(iteration),'Loss: {}'.format(loss_value))\n",
    "\n",
    "#             # if iteration % 1000 == 0:\n",
    "#                 # predict(device, net, flags.initial_words, n_vocab,vocab_to_int, int_to_vocab, top_k=5)\n",
    "#                 # torch.save(net.state_dict(),'checkpoint_pt/model-{}.pth'.format(iteration))\n",
    "                \n",
    "#     return net\n",
    "\n",
    "# rnn_net = train_rnn(words, vocab_to_int, int_to_vocab, len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac9765",
   "metadata": {},
   "source": [
    "**Generate new Shakespeare-style text!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3abccaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text of a specified length with a random starting word using a trained neural network model\n",
    "    \n",
    "def generate_text(device, net, vocab_to_int, int_to_vocab, length, top_k=5):\n",
    "    net.eval()\n",
    "\n",
    "    # Initialize the hidden state\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "\n",
    "    # Randomly choose a starting word from the vocabulary\n",
    "    starting_word = np.random.choice(list(vocab_to_int.keys()))\n",
    "\n",
    "    # Initialize the words list with the starting word\n",
    "    words = [starting_word]\n",
    "\n",
    "    for _ in range(length):\n",
    "        # Convert the current word to its integer representation\n",
    "        ix = torch.tensor([[vocab_to_int[words[-1]]]]).to(device)\n",
    "        \n",
    "        # Get the output and update the hidden state\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        # Get the top-k choices from the output\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        \n",
    "        # Randomly select one of the top-k words\n",
    "        choice = np.random.choice(choices[0])\n",
    "        \n",
    "        # Append the chosen word to the words list\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    generated_text = ' '.join(words)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73286f00",
   "metadata": {},
   "source": [
    "**Load saved Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd26d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save whole model use below code\n",
    "# torch.save(rnn_net, 'model.pth')\n",
    "\n",
    "# To save only the optimized weights of the model use below code\n",
    "# torch.save(rnn_net.state_dict(), 'model_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e195e",
   "metadata": {},
   "source": [
    "*Note:* This first model was trained by 10 epochs. I saved the whole model in this case. Let us load and test it. To test the model just run the code cells and provide desired text length for the \"Enter the desired text length: \". I commented this models output in order to run the seconds model which is trained with longer epochs, but you can uncomment anytime to test also 10 epochs case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52919940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModule(\n",
       "  (embedding): Embedding(32641, 64)\n",
       "  (lstm): LSTM(64, 64, batch_first=True)\n",
       "  (dense): Linear(in_features=64, out_features=32641, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('model_10epoch.pth')\n",
    "rnn_net = model\n",
    "rnn_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad8e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input for text length\n",
    "# desired_length = int(input(\"Enter the desired text length: \"))\n",
    "\n",
    "# generate_text(device, rnn_net, vocab_to_int, int_to_vocab, desired_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c93d6",
   "metadata": {},
   "source": [
    "*Note:* This second model was trained by 50 epochs. I saved the not whole model in this case, but model dict. Let us load and test it. To test the model just run the code cells and provide desired text length for the \"Enter the desired text length: \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "704d0055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the desired text length: 600\n",
      "door abashd the queen I am so far a little thing I would you had crossd this to the lordly beast To make me to your own be as much as the shepherd and my good father And that he hath made me not the very tip and a king but I am not bookish for your own and the king and I am so and so I am a courtier To make a word a gentleman to have you to me And that I am sorry for your worship to be my master If you were a fool and a thousand thousand ducats which I was a thing for you You are welcome Travel sir THERSITES I will be so excellently if merchantlike she coyd today She shall have a sheep in a king That were in a semicircle with a man of all skins Of the warden Timon Civil exile are hurt from a barbarous Long art not so if he were a man of his wrath illustrious generals why dost but not have been done I know it is my lord my good friend I am I know to the success to me and all the welfare for my love That you shall have a thousand thousand pound the kings highway to your worship and that you are a good friend And so I think that the great and ever I have heard of my good father in this time of this I would I had a time To bear a sonnet to Supply my head and so and that he was not so angerd to you not to be equalldthus thy father was beyond his fills That you shall have me leave I do believe him to me at the opening Of the news of your purse I think you have heard you well to see the king I know it not but the devil a good piece I was a gentleman I think you are welcome and the most accursed happiness and be a good man I must be a doubledealer again to him And for my mind and I am I to my master How now whats your highness sons I have heard you not I will have the time I have heard you to my heart of your departure Can I go you for this to be fantastic Seeking the queen of the court And so I will have no more to you with me to my lord And for a little more and traditional passive a great ale of him I will have not seen my master but this way is the king That I am glad of the sleevehand shepherd for my life And so much as the sea To have the ordering a most incomparable negatives is thy commixtion longing and the feeders winks Tonight before Crosby THESEUS As near the prettiest difference Of a thousand pound a thousand pound a fool I have heard you all too I think I was born of his life And that is the matter for my lord I will be not a man and the more as I would have done And so I do remit your ladyship and your petitions to me as a man I think that you must be so unsuitable int but as the unthoughton praise may be a fool I have heard him to my life To have him to the most deeply of our business appertaining not to the Fool and appointed her Enter SILVIA above and the Gaoler with his helm and the old one and the\n"
     ]
    }
   ],
   "source": [
    "# Define a new instance of RNNModule\n",
    "loaded_rnn_net = RNNModule(len(vocab), seq_size, embedding_size, lstm_size)\n",
    "loaded_rnn_net = loaded_rnn_net.to(device)\n",
    "\n",
    "# Load the saved state dictionary\n",
    "loaded_rnn_net.load_state_dict(torch.load('model_dict_50epoch.pth'))\n",
    "loaded_rnn_net.eval()\n",
    "\n",
    "# User input for text length\n",
    "desired_length = int(input(\"Enter the desired text length: \"))\n",
    "\n",
    "# Use a random starting word for prediction\n",
    "generate_text(device, loaded_rnn_net, vocab_to_int, int_to_vocab, desired_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
